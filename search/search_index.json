{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Toolchest","text":"<p>If you're ready to start building, head straight to Installation,  Running Bioinformatics Packages with Toolchest, or  Custom Python Functions and Containers.</p>"},{"location":"#what-does-toolchest-do","title":"What does Toolchest do?","text":"<p>Toolchest is an open source library for running computational biology software in the cloud.  For software that has  reference databases, Toolchest comes with pre-built reference DBs on our high-speed cloud database store \u2013 or you can  add your own.</p> <p>Toolchest handles input and output file transfer as well as cloud resource provisioning. That means you can use the  Toolchest library from anywhere you write Python, including Jupyter notebooks or a Python function \u2013 on your computer or  in the cloud.</p>"},{"location":"#who-should-use-toolchest","title":"Who should use Toolchest?","text":"<p>If you:</p> <ul> <li>use bioinformatics software that runs on the command line, but you write code in Python</li> <li>have functions that need more resources than your laptop, but you don't want to manage your own cloud infrastructure</li> <li>handle a lot of data</li> </ul> <p>then you should try Toolchest!</p>"},{"location":"#what-doesnt-toolchest-solve","title":"What doesn't Toolchest solve?","text":"<ul> <li>Pipelining (see Prefect, Dagster, Nextflow, or Snakemake)</li> <li>Data versioning or management</li> </ul>"},{"location":"#why-toolchest","title":"Why Toolchest?","text":"<ul> <li>You can scale instantly with Toolchest; Toolchest is built on top of AWS</li> <li>You don't need an AWS account! Toolchest jobs run in our own AWS account by default</li> <li>Cloud resources are spun up and down immediately, maximizing efficiency and reducing idling resources</li> </ul>"},{"location":"feature-reference/adding-and-updating-custom-databases/","title":"Adding and Updating Custom Databases","text":"<p>You can add or update custom reference databases using Toolchest\u00a0\u2013 the interface is the same as running any tool,  except <code>inputs</code> is replaced by <code>database_path</code>.</p> <p>Adding and updating databases function as Async Runs. The <code>add_database</code> and  <code>update_database</code> functions return after transferring the data with:</p> <ul> <li>a unique ID that you can use with <code>.get_status()</code> to track status</li> <li>the new <code>database_name</code> and <code>database_version</code></li> </ul>"},{"location":"feature-reference/adding-and-updating-custom-databases/#adding-a-custom-database","title":"Adding a Custom Database","text":"<p>You can add a custom database for any tool that exists in Toolchest. </p> <p>The custom database must already be generated for the specific tool. For example, the custom database for Kraken 2 must  be generated by <code>kraken2-build</code> rather than a collection of FASTQ files.</p> <p>Arguments:</p> <ul> <li><code>database_path</code>:  Path or list of paths (local or S3) to file(s) containing the custom database. This can also be a single path to a directory; see this section.</li> <li><code>tool</code>: Toolchest tool class with which you use the database (e.g. <code>toolchest.tools.DiamondBlastp</code>,  <code>toolchest.tools.Kraken2</code>).</li> <li><code>database_name</code>: Name of the new custom database.</li> <li><code>database_primary_name</code>: If you are uploading multiple database files and your tool takes in a certain file or prefix  instead of the whole directory as its command-line argument, use this to specify the name of that file or prefix. See this section for more details.</li> </ul> <p>The return is a <code>Toolchest.api.Output</code> object, containing:</p> <ul> <li><code>database_name</code></li> <li><code>database_version</code></li> <li><code>run_id</code></li> </ul> <p>Here's an example of adding a custom database for Kraken 2 using an S3 prefix URI.</p> <pre><code>import toolchest_client as tc\n\ntc.set_key(\"YOUR_KEY\")\n\ntc.update_database(\n  # arbitrary-directory is a prefix containing files like arbitrary-directory/db.files.1\n  database_path=\"s3://example-s3-bucket/arbitrary-directory/\",\n  tool=tc.tools.Kraken2,\n  database_name=\"example-db-name\",\n  database_primary_name=\"db.files\",\n)\n</code></pre> <p>When will my database be ready to use?</p> <p>It takes time for the database to transfer to our system. Once the add / update run has a status of  <code>ready_to_transfer_to_client</code>, you're good to go. You can check the status  with these steps.</p>"},{"location":"feature-reference/adding-and-updating-custom-databases/#updating-a-custom-database","title":"Updating a Custom Database","text":"<p>You can create a new custom version for any tool and database in Toolchest. This is very similar to adding a custom  database, except the <code>database_name</code> for the database must already exist.</p> <p>Arguments:</p> <ul> <li><code>database_path</code>:  Path or list of paths (local or S3) to file(s) containing the custom database. This can also be a single path to a directory; see this section.</li> <li><code>tool</code>: Toolchest tool class with which you use the database (e.g. <code>toolchest.tools.DiamondBlastp</code>,  <code>toolchest.tools.Kraken2</code>).</li> <li><code>database_name</code>: Name of the existing database.</li> <li><code>database_primary_name</code>: If you are uploading multiple database files and your tool takes in a certain file or prefix  instead of the whole directory as its command-line argument, use this to specify the name of that file or prefix. See this section for more details.</li> </ul> <p><code>database_primary_name</code> is optional for <code>update_database</code></p> <p>If omitted, it assumes the same <code>database_primary_name</code> as the previous version of the custom database.</p> <p>Returns a <code>Toolchest.api.Output</code> object, containing:</p> <ul> <li><code>database_name</code></li> <li><code>database_version</code> (auto-incremented from the latest version)</li> <li><code>run_id</code></li> </ul> <p>Here's an example update of the standard Kraken 2 database:</p> <pre><code>import toolchest_client as tc\n\ntc.set_key(\"YOUR_KEY\")\n\ntc.update_database(\n  database_path=[\n    \"s3://example-s3-bucket-for-databases/my_db_directory/db.files.1\",\n    \"s3://example-s3-bucket-for-databases/my_db_directory/db.files.2\",\n  ],\n  tool=tc.tools.Kraken2,\n  database_name=\"standard\",\n  database_primary_name=\"db.files\",\n)\n</code></pre>"},{"location":"feature-reference/adding-and-updating-custom-databases/#preserving-file-structure","title":"Preserving File Structure","text":"<p>You can use a directory as your <code>database_path</code>. For both local and S3 paths, using a directory will place all files in their implied subdirectories.</p> <p>If a list of paths is used instead, file structure will not be preserved. All files will be placed into  the same directory.</p>"},{"location":"feature-reference/adding-and-updating-custom-databases/#using-database_primary_name","title":"Using <code>database_primary_name</code>","text":"<p>Let's say you have a tool that you would run from the command line like this: <pre><code>some_command --database databases/my_db\n</code></pre> For custom databases, we can't be sure about what <code>databases/my_db</code> actually is. <code>my_db</code> could either represent a directory, a file itself, or multiple files -- it depends on the context of the tool. </p> <p>To pass that context to Toolchest, use <code>database_primary_name</code>. If <code>--database</code> refers to a path that isn't a directory,  use <code>database_path</code> for the directory and <code>database_primary_name</code> for the filename or prefix.</p> <p>Here's an example call for Bowtie 2, where <code>my_db</code> is a prefix for multiple files within <code>databases/</code>: <pre><code>import toolchest_client as tc\ntc.add_database(\n    tool=tc.tools.Bowtie2,\n    database_name=\"example_name_for_my_new_database\",\n    database_path=\"databases/\",\n    database_primary_name=\"my_db\",\n)\n</code></pre></p>"},{"location":"feature-reference/adding-and-updating-custom-databases/#use-cases","title":"Use cases","text":"<ol> <li>If your database is a directory itself, such as <code>databases/my_db/{various database files}</code>, then use  <code>database_primary_name=None</code>: <pre><code>tc.add_database(\n    database_path=\"databases/my_db\",\n    database_primary_name=None,\n    ...\n)\n</code></pre></li> <li>If your database is a single database file, such as <code>databases/my_db</code>, or a prefix, such as: <pre><code>databases/\n\u251c\u2500\u2500 my_db.file1\n\u251c\u2500\u2500 my_db.file2\n\u2514\u2500\u2500 my_db.file3\n</code></pre> then use <code>database_primary_name=my_db</code>: <pre><code>tc.add_database(\n    database_path=\"databases/\",\n    database_primary_name=\"my_db\",\n    ...\n)\n</code></pre></li> </ol>"},{"location":"feature-reference/adding-and-updating-custom-databases/#behavior-differences-for-update_database","title":"Behavior differences for <code>update_database</code>","text":"<p>For <code>update_database</code>, <code>database_primary_name</code> is optional. If omitted, it assumes the same value as the  previous version of the custom database.</p> <p>If <code>database_primary_name</code> needs to be changed to <code>None</code>  for future versions of the database, contact Toolchest to update the primary name.</p>"},{"location":"feature-reference/adding-and-updating-custom-databases/#security","title":"Security","text":"<p>By default, the privacy setting of all custom databases is the equivalent of \"unlisted\". This means that if anybody  else knows the name and version of your database, they can access it.</p> <p>We support fully private custom databases as a part of the managed-hosted and on-prem versions of Toolchest.</p>"},{"location":"feature-reference/async-runs/","title":"Asynchronous Runs","text":"<p>Toolchest supports async execution for every tool. Async runs are useful long running commands, because you do not need to keep an open terminal or connection while Toolchest is executing.</p> <p>We've seen people use async runs from AWS Lambda functions, custom automated pipelines, and manual calls from IDEs.</p>"},{"location":"feature-reference/async-runs/#launching-an-async-run","title":"Launching an Async Run","text":"<p>To launch an async run, ad the <code>is_async</code> parameter with the value True in your function call. For example,  using the <code>test</code> function:</p> <pre><code>my_run = tc.test(\n    inputs=\"./\",\n    output_path=\"./output\",\n    is_async=True,\n)\n</code></pre> <p>After the Toolchest run is initialized and all file transfers are complete, the Toolchest call returns an  output object containing a run ID.</p> <p>You can check your run status using the returned run ID (e.g. <code>my_run.run_id</code>).</p> <p>Once you see this, Toolchest is executing your run in the background, and you're safe to close your terminal. (Be sure  to record the run ID!)</p>"},{"location":"feature-reference/async-runs/#checking-run-status","title":"Checking Run Status","text":"<p>To check the status of your async run, call the <code>get_status</code> function with your run ID.</p> <pre><code>print(tc.get_status(run_id=\"YOUR_RUN_ID\"))\n'executing'\n</code></pre> <p><code>get_status</code> returns a string. Once the status is <code>ready_to_transfer_to_client</code>, the run has finished execution and  is ready to download.</p>"},{"location":"feature-reference/async-runs/#statuses-enum","title":"Statuses enum","text":"<p>There's an enum \u2013<code>Status</code> \u2013 that contains all statuses returned from <code>get_status()</code>. You can check statuses against  this enum for custom error handling, progress tracking, or whatever you're building.</p> <pre><code>status = tc.get_status(run_id=\"YOUR_RUN_ID\")\nif status == tc.Status.COMPLETE:\n  print(\"AlphaFold run finished! Sending email to researcher...\")\n</code></pre> <p>To check all possible enum values, you can print the enum as a list:</p> <pre><code>print(list(tc.Status))\n[&lt;Status.INITIALIZED: 'initialized'&gt;, ...\n</code></pre>"},{"location":"feature-reference/async-runs/#downloading-output","title":"Downloading Output","text":"<p>To download the output manually, call the <code>download</code> function with your run ID and output directory.</p> <pre><code>tc.download(\n    run_id=\"YOUR_RUN_ID\", \n    output_path=\"./output/\",\n)\n</code></pre> <p>This downloads the run's output file(s) into the output directory. You can run <code>download</code> for 7 days after starting the  run.</p>"},{"location":"feature-reference/authentication/","title":"Authentication","text":"<p>To run Toolchest jobs, you'll need a Toolchest key. If you don't have one yet, you can get a key  here.</p>"},{"location":"feature-reference/authentication/#setting-a-key","title":"Setting a Key","text":"<p>Use the <code>set_key</code> function to authenticate your Toolchest calls:</p> <pre><code>import toolchest_client as tc\ntc.set_key(\"YOUR_TOOLCHEST_KEY\")\n</code></pre> <p><code>YOUR_TOOLCHEST_KEY</code> should be a string containing either the key value or a path to a file containing the key.</p> <p>You can also set your key through the <code>TOOLCHEST_KEY</code> environment variable.</p>"},{"location":"feature-reference/authentication/#getting-a-stored-key","title":"Getting a Stored Key","text":"<p>To check the value of the key in use, use the <code>get_key</code> function, which returns a string containing your key value.</p> <pre><code>import toolchest_client as tc\ntc.get_key()\n</code></pre>"},{"location":"feature-reference/authentication/#private-tools-and-databases","title":"Private Tools and Databases","text":"<p>If you'd like to use a private tool database with Toolchest without exposing it to the public, Toolchest supports  restricting some databases and tools to your account.</p>"},{"location":"feature-reference/output-objects/","title":"Output Objects","text":"<p>Every Toolchest run returns an object containing the run ID (<code>run_id</code>), local paths to downloaded output files  (<code>output_path</code>), and more.</p> <p>As an example, we'll use the output from this <code>test</code> function call, but you can do this for any Toolchest tool:</p> <pre><code>import toolchest_client as tc\n\ntoolchest_output = tc.test(\n    inputs=\"./\",\n    output_path=\"./output/\",\n    tool_args=\"\",\n)\n</code></pre>"},{"location":"feature-reference/output-objects/#run-metadata","title":"Run Metadata","text":"<p>The <code>run_id</code> instance variable contains the ID of the Toolchest run, stored as a string. </p> <p>Likewise, the <code>output_path</code> instance variable contains local paths to downloaded output files.</p> <pre><code>&gt;&gt;&gt; toolchest_output.run_id\n'00000000-0000-0000-0000-000000000000'  # this will be your custom run ID\n&gt;&gt;&gt; toolchest_output.output_path\n'OUTPUT_DIR/test_output.txt'\n</code></pre> <p>You can store and use the <code>run_id</code> check the run's status with Async Runs.</p> <p><code>output_path</code> will be a string (for 1 output file), a list of strings (for multiple output files), or a null value (if  download was skipped).</p>"},{"location":"feature-reference/output-objects/#download","title":"Download","text":"<p>You can also directly call the <code>download</code> function from the output object to download (or re-download) the outputs. </p> <pre><code>toolchest_output.download(\n    output_path=\"./\",\n)\n</code></pre> <p>However, keep in mind that Toolchest only retains your job's output for 7 days after job execution.</p>"},{"location":"feature-reference/output-streaming/","title":"Live-Streaming Tool Output","text":"<p>For synchronous runs for Python and Lug, Toolchest supports streaming remote output live to wherever you're running  Toolchest.</p> <p>For example, here's a <code>python3</code> Toolchest call with streaming enabled and an example script: <pre><code>import toolchest_client as tc\ntc.set_key(\"YOUR_KEY\")\ntc.python3(\n    script=\"script.py\",\n    streaming_enabled=True,\n)\n</code></pre></p> <pre><code># script.py\nimport time\nfor letter in [\"A\", \"B\", \"C\"]:\n    print(f\"Hello world {letter}\")\n    time.sleep(1)\n</code></pre> <p>You'll see the following lines printed as they are generated by the remotely-running Python script, one line per second: <pre><code>Hello world A\nHello world B\nHello world C\n</code></pre></p> <p>Streaming and cancelling runs</p> <p>With streaming enabled, tool execution terminates if the streaming connection is broken. This includes cancelling your job by entering Ctrl-C. </p> <p>If a job is cancelled before encountering a bug in your script, the error may not be visible in Toolchest logs.</p>"},{"location":"feature-reference/output-streaming/#supported-tools","title":"Supported Tools","text":"<p>Output streaming is supported for <code>python3</code> and <code>lug</code>. For both, streaming is enabled by default.</p>"},{"location":"feature-reference/using-aws-with-toolchest/","title":"Using AWS with Toolchest","text":"<p>Toolchest supports reading and writing from your S3 buckets. You can also run Toolchest within your own AWS account, so the files you pass to <code>inputs</code> and <code>output_path</code> aren't transferred outside your account.</p>"},{"location":"feature-reference/using-aws-with-toolchest/#input-files","title":"Input Files","text":"<p>Files stored on S3 can be passed in as inputs, using the file's S3 URI.  For example: s <pre><code>tc.kraken2(\n    inputs=\"s3://toolchest-demo-data/SRR16201572_R1.fastq\",\n    output_path=\"./\",\n)\n</code></pre></p>"},{"location":"feature-reference/using-aws-with-toolchest/#output-to-s3","title":"Output to S3","text":"<p>Some tools support uploading outputs directly to your custom S3 bucket. For these runs, put the S3 bucket + prefix in  <code>output_path</code>. For example:</p> <pre><code>tc.kraken2(\n    inputs=\"./example.fastq\",\n    output_path=\"s3://your-output/your-intended-subfolder\",\n)\n</code></pre>"},{"location":"feature-reference/using-aws-with-toolchest/#custom-databases","title":"Custom Databases","text":"<p>For some tools, you can use use a custom database stored on S3 using <code>custom_database_path</code>:</p> <pre><code>tc.kraken2(\n    inputs=\"./example.fastq\",\n    output_path=\"./example_output_dir\",\n    custom_database_path=\"s3://your-databases/your-kraken2-database\",\n)\n</code></pre> <p>Toolchest needs permission to list and copy all of the files in the S3 prefix you use.</p>"},{"location":"feature-reference/using-aws-with-toolchest/#granting-permissions-to-toolchest-to-access-your-s3-bucket","title":"Granting Permissions to Toolchest to Access Your S3 Bucket","text":"<p>To grant Toolchest access to your S3 bucket, use this policy:</p> <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Sid\": \"Toolchest\",\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"AWS\": \"arn:aws:iam::172533437917:role/toolchest-worker-node-role\"\n},\n\"Action\": [\n\"s3:GetObject\",\n\"s3:ListBucket\"\n],\n\"Resource\": [\n\"arn:aws:s3:::YOUR_BUCKET_NAME\",\n\"arn:aws:s3:::YOUR_BUCKET_NAME/*\"\n]\n}\n]\n}\n</code></pre> <p>(Make sure to replace<code>YOUR_BUCKET_NAME</code> with your bucket)</p> <p>You can restrict this to specific files or prefixes with whatever IAM policy you'd like, just make sure that Toolchest  has <code>s3:GetObject</code> for any file you'll use with Toolchest and <code>s3:ListBucket</code> permissions for any prefix.</p> <p>After you add this policy, let us know and we'll complete the setup process!</p>"},{"location":"feature-reference/using-aws-with-toolchest/#running-toolchest-in-your-own-aws-account","title":"Running Toolchest in Your Own AWS Account","text":"<p>You can run Toolchest in your own AWS account, and the data that you pass to <code>inputs</code> and <code>output_path</code> doesn't leave  your own AWS environment. Get in touch with us if you'd like to know more!</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Note: if you haven't already, make sure you have an API key!</p>"},{"location":"getting-started/installation/#with-pip","title":"With <code>pip</code>","text":"<pre><code>pip install toolchest-client\n</code></pre>"},{"location":"getting-started/installation/#with-poetry","title":"With Poetry","text":"<pre><code>poetry add toolchest-client\n</code></pre>"},{"location":"getting-started/installation/#supported-python-versions","title":"Supported Python versions","text":"<p>We support Python 3.7 through the latest Python 3.11 release candidate.</p>"},{"location":"getting-started/installation/#supported-operating-systems","title":"Supported operating systems","text":"<p>You can run Toolchest on most recent versions of macOS, Linux and Windows.</p>"},{"location":"getting-started/python-functions-and-containers/","title":"Deploying Python Functions and Docker Images","text":"<p>If you have custom Python functions that need more power, you can deploy those to the cloud using Toolchest as well!</p> <p>This tends to work well with:</p> <ul> <li>custom command-line software that's packed in a Docker image</li> <li>packages that aren't on Toolchest yet</li> <li>or where you just have </li> </ul> <p>To do this, we recommend using Lug, a fully open-source project that builds on top of Toolchest.</p>"},{"location":"getting-started/running-bioinformatics-on-toolchest/","title":"Toolchest-wrapped Command-line Software","text":"<p>Note: if you haven't already, make sure you have an API key and Toolchest is installed!</p> <p>The most popular bioinformatics software is run through the command line. Toolchest wraps this software in Python and  runs it on the cloud.</p>"},{"location":"getting-started/running-bioinformatics-on-toolchest/#a-quick-start","title":"A quick start","text":"<p>To get started, we'll use STAR, but you can use any of the packages supported by Toolchest . On the command-line, running STAR looks like:</p> <pre><code>STAR --outFileNamePrefix ./output_path --genomeDir ./database_CRCh38 --readFilesIn ./inputs/\n</code></pre> <p>With Toolchest, it's:</p> <pre><code>import toolchest-client as tc\n\ntc.set_key(\"YOUR_KEY\")\n\ntc.STAR(\n    read_one=\"s3://toolchest-demo-data/SRR2557119_small.fastq\",\n    output_path=\"./output_path/\",\n    database_name=\"GRCh38\",\n)\n</code></pre> <p>and it runs in the cloud! Breaking down the arguments:</p> <ul> <li><code>read_one</code> is for input files. They can be on your computer, or somewhere else like S3.</li> <li><code>output_path</code> is where your output files are written. This can also be your computer, or somewhere else like S3.</li> <li><code>database_name</code> is the name of the Toolchest-hosted database.</li> </ul>"},{"location":"getting-started/running-bioinformatics-on-toolchest/#adding-more-options","title":"Adding more options","text":"<pre><code>import toolchest-client as tc\n\ntc.set_key(\"YOUR_KEY\")\n\ntc.STAR(\n    read_one=\"s3://toolchest-demo-data/SRR2557119_small.fastq\",\n    output_path=\"./output/\",\n    database_name=\"GRCh38\",\n    database_version=\"1\",\n    tool_args=\"--outSAMtype BAM Unsorted\"\n)\n</code></pre> <p>We added two new arguments: - <code>database_version</code> is the version number of the Toolchest-hosted database. - <code>tool_args</code> are the arguments that you would normally set on the command-line to customize execution.</p> <p>Next, let's learn more about what kinds of files you can use with Toolchest.</p>"},{"location":"getting-started/using-files/","title":"Using Files","text":"<p>Toolchest works with files on your computer (local files) or files on something like S3 (remote files). We recommend  using local or S3 files for data integrity and speed of execution, but HTTP or FTP URLs are supported too.</p> <p>For all tools and file types, <code>inputs</code> takes a string path or a list of paths. <code>output_path</code> always takes a directory  path.</p> <p>Let's take a look at what it looks like to use different types of local and remote paths!</p> <p>You can mix and match file sources</p> <p>You can mix and match local and remote files in the same call. Every file is handled independently, so you can use S3,  FTP, and local files together.</p>"},{"location":"getting-started/using-files/#local-files-and-directories","title":"Local files and directories","text":"<p>Local files are the most intuitive: you just pass normal paths directly to Toolchest. In the background, the files are  transferred to and from the cloud.</p> <p><code>inputs</code> takes paths to files and directories.</p> <p><code>output_path</code> takes a path to a directory. Output files are written in this directory.</p>"},{"location":"getting-started/using-files/#local-directory-inputs","title":"Local directory inputs","text":"<p>If a directory is passed, all files within the directory are used as input. Directory structure will be destroyed unless <code>compress_inputs=True</code> is provided as an argument.</p> <p>For example if you have the following directory structure: <pre><code>/path/to/base/directory/\n    subdirectory_one/\n        input.fastq\n    subdirectory_two/\n        input.fastq\n        info.txt\n</code></pre> and you used the following toolchest call: <pre><code>tc.test(\n    inputs=\"/path/to/base/directory/\",\n    compress_inputs=True\n)\n</code></pre> Then the input files will retain the directory structure without name conflicts. If <code>compress_inputs</code> is set to <code>False</code> or not provided, the 2 <code>inputs.fastq</code> would overwrite whichever one was downloaded second. </p>"},{"location":"getting-started/using-files/#remote-files","title":"Remote files","text":""},{"location":"getting-started/using-files/#aws-s3","title":"AWS S3","text":"<p>S3 files are the fastest and most reliable input source. Toolchest pulls directly from the path you pass.</p> <ul> <li><code>inputs</code> takes S3 URIs for a file. If you have multiple files in an S3 directory, make sure to list the directory first  and pass each file as an input.</li> <li><code>output_path</code> accepts an S3 URI for a S3 prefix.</li> </ul> <p>Here's an example using the <code>test</code> package with an S3 input: <pre><code>tc.test(\n    inputs=\"s3://toolchest-public-examples/example.fastq\",\n    output_path=\"s3://toolchest-public-output/remote-output/\"\n)\n</code></pre></p> <p>Make sure Toolchest has access to your S3 bucket</p> <p>To grant Toolchest access, see AWS Integration.</p>"},{"location":"getting-started/using-files/#httphttps","title":"HTTP/HTTPS","text":"<p>HTTP and HTTPS files are dangerous!</p> <p>We can't guarantee data integrity on transfer, because different servers behave differently. Make sure that the HTTP  server supports <code>GET</code> requests with the <code>range</code> header. Always use a local or S3 file path if possible. Ye be warned!</p> <ul> <li><code>inputs</code> takes an HTTP URL for a file. If you have multiple files in an HTTP directory, make sure to list the directory  first, and pass each file as an input.</li> <li><code>output_path</code> does not accept HTTP outputs at this time.</li> </ul> <p>Here's an example using the <code>test</code> package with an HTTP input: <pre><code>tc.test(\n    inputs=\"https://rest.uniprot.org/uniprotkb/P48754.fasta\",\n    output_path=\"./\"\n)\n</code></pre></p>"},{"location":"getting-started/using-files/#ftp","title":"FTP","text":"<p>FTP files are dangerous!</p> <p>We can't guarantee data integrity on transfer, because different servers behave differently. Always use a local or S3  file path if possible. Ye be warned!</p> <ul> <li><code>inputs</code> accepts an FTP URL for a file. If you have multiple files in an FTP directory, make sure to list the  directory first, and pass each file as an input.</li> <li><code>output_path</code> does not accept FTP outputs at this time.</li> </ul> <p>Here's an example using the <code>test</code> package with an FTP input: <pre><code>tc.test(\n    inputs=\"ftp://ftp.sra.ebi.ac.uk/vol1/fastq//SRR999/000/SRR9990000/SRR9990000.fastq.gz\",\n    output_path=\"./\"\n)\n</code></pre></p>"},{"location":"tool-reference/about/","title":"About the Tool Reference","text":"<p>This section contains documentation for the core \"tools\" that make up Toolchest: the aligners, assemblers, classifiers,  and other software that Toolchest wraps.</p>"},{"location":"tool-reference/aligners/","title":"Aligners","text":"<p>Aligners find the similarity between two or more sequences. Sometimes, query sequences are compared against a reference  database in a sort of fuzzy search (e.g. Bowtie 2). In other contexts, several query sequences are compared against one another (e.g. Clustal Omega).</p> <p>Most aligners are tailored for specific types of data: STAR for single-cell RNA-Seq,  DIAMOND BLASTP for protein sequences against a protein database, and  DIAMOND BLASTX for translated nucleotide sequences against a protein database.</p> <p>Toolchest hosts both the aligner and the reference databases, and you can also  use your own custom database.</p> <p>If you don't need the extra information that aligners return \u2013 e.g. for some microbiome taxonomic classification \u2013  you can also use a more efficient classifier.</p> <p>If you want to use an aligner that's not listed here, let us know! It might  already be available on our infrastructure but not documented.</p>"},{"location":"tool-reference/all-other-tools/","title":"All Other Tools","text":"<p>Before any tool lands in our documentation, we add publicly exposed integration tests to ensure data quality.</p> <p>If you want to use a tool not listed above, please let us know! Some are in private beta as we test and verify their functionality, and we're rapidly adding more.</p>"},{"location":"tool-reference/assemblers/","title":"About Assemblers","text":"<p>Genome assemblers take partial sequences of a genome and assemble them to form a larger contiguous sequence \u2013\u00a0ideally, the whole genome.</p> <p>The best assemblers work with both short reads (e.g. Illumina) and long reads (e.g. Oxford Nanopore) to quickly assemble a genome (e.g. Unicycler).</p> <p>If you want to use an assembler that's not listed here, let us know! It might even be already available on our infrastructure but not listed.</p>"},{"location":"tool-reference/demultiplexers/","title":"About Demultiplexers","text":"<p>Demultiplexing is extracting components from something that's all mixed together. It's like taking a rope and unwinding each individual thread.</p> <p>Sometimes, this means using a straightforward tool like <code>bcl2fastq</code> to generate FASTQs from raw Illumina NGS reads.  Just for fun, we've also included an ML-based tool called Demucs to separate song tracks.</p>"},{"location":"tool-reference/post-processing/","title":"About Post-Processing","text":"<p>Some tools modify your raw data, but you still need another tool to bring the data to a usable state. We call that a  post-processing tool.</p> <p>One example is Kraken, often used with Bracken for  post-processing.</p>"},{"location":"tool-reference/pre-processing/","title":"About Pre-Processing","text":"<p>Some tools can check data integrity or transform data before use in another tool. We call that a pre-processing tool.</p>"},{"location":"tool-reference/python3/","title":"Python 3","text":"<p>This probably isn't the page you're looking for</p> <p>To run Python functions and Docker images with Toolchest, check out Lug, an open-source  project that builds on Toolchest.</p> <p>Python is the favorite language of many computational biologists. Unfortunately, running Python on your computer reaches its limits quickly while analyzing biological data. The way most researchers get more power is by starting a cloud instance, SSHing in, and running their Python script in the cloud.</p> <p>Companies like Stripe have internal tooling for their engineers to train machine learning models in the cloud. It replaces the process of starting a cloud instance, SSHing in, starting the script, and then copying the results.</p> <p>You get the same tooling with Toolchest: in the background, Toolchest starts a cloud instance, runs your script on the instance, and copies the input and output files. You only get charged when your script is running on the instance, which means you don't have to pay for idling cloud instances \u2013\u00a0or pay thousands of dollars after forgetting to terminate instances.</p>"},{"location":"tool-reference/python3/#example-usage","title":"Example usage","text":"<p>Let's say we want to:</p> <ol> <li>Calculate the length of <code>input.txt</code> with a Python script called <code>calculate_length.py</code></li> <li>Return the length of a file at <code>./my_output/length.txt</code></li> </ol> <p>The Toolchest call is:</p> <pre><code>file_to_count = \"input.txt\"\nlength_file = \"length.txt\"\n\ntc.python3(\n    script=\"calculate_length.py\",\n    inputs=[file_to_count],\n    output_path=\"./my_output/\",\n    tool_args=f\"--input-file {file_to_count} --length-file {length_file}\",\n)\n</code></pre> <p>In the Python script, inputs are read from <code>./input/</code>, and output is written to <code>./output/</code>. That's because Toolchest places input files at <code>./input/</code>, and it only captures output files written to <code>./output/</code>.</p> <p>The script, <code>calculate_length.py</code>, contains:</p> <pre><code>import argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--input-file', metavar='input', help=\"Input file\")\nparser.add_argument('--length-file', metavar='length', help=\"Output file\")\nargs = parser.parse_args()\n\nwith open(f\"./input/{args.input}\", \"r\") as input_file:\n    input_file_contents = input_file.read()\n\nwith open(f\"./output/{args.length}\", \"w\") as output_file:\n    output_file.write(f\"{len(input_file_contents)}\")\n</code></pre>"},{"location":"tool-reference/python3/#the-toolchest-call","title":"The Toolchest call","text":"<p><pre><code>tc.python3(\n    script,\n    inputs,\n    output_path=None,\n    tool_args=\"\",\n    is_async=False,\n    streaming_enabled=True,\n)\n</code></pre> <pre><code>toolchest$python3(\nscript,\ninputs,\noutput_path = NULL,\ntool_args = \"\",\nis_async = FALSE\n)\n</code></pre></p>"},{"location":"tool-reference/python3/#custom-environments","title":"Custom environments","text":"<p>By passing a Docker image to Toolchest using <code>custom_docker_image_id</code>, you can run Python in any environment you'd like via Toolchest.</p> <p>Make sure that the Docker image you use:</p> <ul> <li>Has <code>python3</code> (i.e. <code>docker run {image} python3</code> works)</li> <li>Supports the <code>linux/amd64</code> platform</li> <li>Exists on the machine where you're running Toolchest, and that the Docker engine is running</li> </ul> <p>If you're building the image on an M1 Mac or Windows machine, make sure you build your Docker image with platform set to <code>linux/amd64</code>.</p>"},{"location":"tool-reference/python3/#building-and-using-a-custom-environment","title":"Building and using a custom environment","text":"<p>In this guide, we'll build and run a custom Docker image that supports numpy via Toolchest.</p> <p>Before starting, make sure that Docker engine is installed and running.</p> <p>Start by creating a file named <code>Dockerfile</code> that contains Python 3.9 and numpy:</p> <p>```dockerfile Dockerfile FROM python:3.9 RUN pip install numpy <pre><code>Next, build a Docker image from that Dockerfile.\n\n```shell\ndocker build . -t python3-numpy:3.9 --platform linux/amd64\n</code></pre> <pre><code># Make sure the Docker Python library is installed (e.g. pip install docker)\nimport docker \n\nclient = docker.from_env()\nclient.images.build(\n  path=f\"./\", # This is a path to the location of the Dockerfile\n  dockerfile=\"Dockerfile\",\n  tag=\"python3-numpy:3.9\",\n  platform=\"linux/amd64\"\n) \n</code></pre></p> <p>Now let's make a Python script (\"numpy_example.py\") that uses numpy:</p> <pre><code>import numpy as np\n\na = np.array([(1, 2, 3), (4, 5, 6)])\nb = np.array([(7, 8), (9, 10), (11, 12)])\noutput_string = np.array_str(np.matmul(a, b))\n\nf = open(\"./output/output.txt\", \"w\")\nf.write()\nf.close()\n</code></pre> <p>And finally, the last step: you can run the Python script in the custom Docker image using Toolchest:</p> <pre><code>import toolchest_client as tc\n\ntc.python3(\n    script=\"numpy_example.py\",\n    output_path=f\"./local_output/\",\n    custom_docker_image_id=\"python3-numpy:3.9\"\n)\n</code></pre> <p>That's it!</p>"},{"location":"tool-reference/python3/#python-versions","title":"Python versions","text":"<p>Toolchest currently runs version 3.9.1 of Python. You can use other versions of Python by using a custom environment.</p>"},{"location":"tool-reference/python3/#passing-arguments-to-your-python-3-script","title":"Passing arguments to your Python 3 script","text":"<p>Any arguments passed to <code>tool_args</code> are passed to your Python script, as if it were executing on the command line. For example:</p> <pre><code>tc.python3(\n    script=\"my_script.py\",\n    tool_args=\"--my-arg 1234\",\n    ...\n)\n</code></pre> <p>Is processed as if the script were run on the command line like:</p> <pre><code>python3 my_script.py --my-arg 1234\n</code></pre> <p>Some argument names are not allowed due to conflicts with Python itself, including:</p> <ul> <li><code>-c</code></li> <li><code>-i</code></li> <li><code>-m</code></li> </ul>"},{"location":"tool-reference/python3/#return-value","title":"Return value","text":"<p>This function call returns a Toolchest output object, which contains the run ID and locations of downloaded output files. See Output Objects.</p>"},{"location":"tool-reference/python3/#async-runs","title":"Async runs","text":"<p>Set the <code>is_async</code> parameter to <code>True</code> if you would like to run a Python 3 job asynchronously. See Async Runs.</p>"},{"location":"tool-reference/structure-prediction/","title":"About Structure Prediction","text":"<p>Structure prediction takes an input protein sequence and predicts the shape of its three dimensional structure.</p> <p>Recent advances \u2013 including AlphaFold \u2013 make use of deep learning, making use of  GPUs and terabytes of pre-trained reference databases to predict 3D structure.</p> <p>AlphaFold 2 is one of the few structure prediction tools that's hosted on Toolchest, but  let us know if there's another tool that you'd like to use!</p>"},{"location":"tool-reference/taxonomic-classifiers/","title":"About Taxonomic Classifiers","text":"<p>Taxonomic classifiers perform a fuzzy search between input sequences and reference databases. A classic use-case is  determining the relative abundance of a microbiome sample.</p> <p>If you only need relative abundance, you can use a taxonomic profiler that simply returns relative abundance. For a  more detailed view, you can use a classifier like Kraken 2.</p> <p>Toolchest hosts both the taxonomic classifier and the corresponding reference databases, and you can also  use your own custom database.</p> <p>Typically, taxonomic classifiers are more efficient than aligners for taxonomic classification, but most are based on  heuristic methods rather than optimal alignment scores. If you're looking for something more analogous to BLAST, check  out aligners.</p> <p>If you want to use a taxonomic classifier that's not listed here, let us know! It might even be already available on  our infrastructure but not listed.</p>"},{"location":"tool-reference/test-runs/","title":"Test Runs","text":"<p>You can call the <code>test</code> function to mimic a Toolchest run. </p> <p><code>test</code> actually uploads your inputs to Toolchest's infrastructure. Nothing is done to the files beyond the upload.</p>"},{"location":"tool-reference/test-runs/#function-call","title":"Function Call","text":"<pre><code>tc.test(\n    inputs,\n    output_path=None,\n    tool_args=\"\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/test-runs/#output-files","title":"Output Files","text":"<p><code>test</code> has one output file, <code>test_output.txt</code>, a text document that reads:</p> <pre><code>success\n</code></pre>"},{"location":"tool-reference/transfer/","title":"Transfer","text":"<p>Sometimes, there's no alternative to downloading a terabyte of data from an FTP or HTTPS source. When the source  download speed is 5 MB/s (looking at you, NCBI RefSeq and EMBL!), the transfer takes days \u2013 a long time to keep your  laptop up and running.</p> <p><code>transfer</code> moves files from any supported input location to any supported output location. It runs in the background,  meaning you don't need to keep your laptop or server running during transfer.</p>"},{"location":"tool-reference/transfer/#function-call","title":"Function Call","text":"<pre><code>tc.transfer(\n    inputs,\n    output_path=None,\n    is_async=True,\n)\n</code></pre>"},{"location":"tool-reference/transfer/#function-arguments","title":"Function Arguments","text":"Argument Description <code>inputs</code> Path to a file that will be passed in as input. All formats supported by <code>ffmpeg</code> are allowed. The files can be a local or remote, see Using Files. <code>output_path</code> (optional) Path (directory) to where the output files will be downloaded. The path can be a local or remote, see Using Files. <code>is_async</code> Whether to run the job asynchronously. By default, this is true. If you set this to false, the Toolchest command will wait to exit until the transfer is complete. See Async Runs for more."},{"location":"tool-reference/workflows-meta-tools/","title":"About Workflows / Meta-Tools","text":"<p>Workflow tools \u2013 or meta-tools \u2013 wrap several tools to form a unified pipeline. These workflow tools are usually  focused specific area like microbiome or single-cell analysis, but they wrap more generic tools under the hood. </p> <p>They're popular, because they're easy to use; there's no need to make your own choices on aligners, assemblers, or  classifiers, and the tools the workflow creator chooses are often pre-tuned for one specific use-case.</p> <p>HUMAnN is a perfect example of these types of meta-tools. Under the hood, it uses:</p> <ul> <li>Bowtie 2</li> <li>Diamond</li> <li>Python 3</li> <li>RAPSearch2</li> <li>MetaPhlAn 3</li> </ul> <p>and several other tools, all wrapped under the <code>humann</code> command.</p> <p>When using workflow tools via Toolchest, you'll notice a new argument: <code>mode</code>. This lets you run sub-tools directly.</p>"},{"location":"tool-reference/aligners/bowtie-2/","title":"Bowtie 2","text":"<p>Bowtie 2 is a fast and efficient aligner for aligning reads to reference sequences, particularly for input reads of 50-1000 characters and relatively long (e.g. mammalian) reference genomes. For more information, see the tool's Sourceforge page and GitHub repo.</p>"},{"location":"tool-reference/aligners/bowtie-2/#function-call","title":"Function Call","text":"<pre><code>tc.bowtie2(\n    inputs=,\n    output_path=None,\n    tool_args=\"\",\n    database_name=\"standard\",\n    database_version=\"1\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/aligners/bowtie-2/#function-arguments","title":"Function Arguments","text":"Argument Use in place of: Description <code>inputs</code> <code>-U</code> Path to one or more files to use as input. The files can be a local or remote, see Using Files. <code>output_path</code> <code>-S</code> (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to Bowtie 2. This should be a string of arguments like the command line. See Supported Additional Arguments for more details. <code>database_name</code> <code>-x</code>* (optional) Name of database to use for Bowtie 2 alignment. Defaults to <code>\"GRCh38_noalt_as\"</code> (human genome). <code>database_version</code> <code>-x</code>* (optional) Version of database to use for Bowtie 2 alignment. Defaults to <code>\"1\"</code>. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>See the Databases section for more details.</p>"},{"location":"tool-reference/aligners/bowtie-2/#output-files","title":"Output Files","text":"<p>A Bowtie 2 run will output these files into  <code>output_path</code>:</p> <ul> <li><code>bowtie2.log</code>: Log outputted to <code>stderr</code>.</li> <li><code>bowtie2_output.sam</code>: SAM file outputted by Bowtie 2.</li> </ul>"},{"location":"tool-reference/aligners/bowtie-2/#notes","title":"Notes","text":""},{"location":"tool-reference/aligners/bowtie-2/#paired-end-inputs","title":"Paired-end inputs","text":"<p>Paired-end read inputs can be provided through <code>inputs</code>.</p>"},{"location":"tool-reference/aligners/bowtie-2/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 2.4.4. of Bowtie 2. </p>"},{"location":"tool-reference/aligners/bowtie-2/#databases","title":"Databases","text":"<p>Toolchest currently supports the following databases for Bowtie 2:</p> <code>database_name</code> <code>database_version</code> Description <code>Ash1_v2.0</code> <code>1</code> Human / Ash2.0, JHU source1 <code>GRCh38_noalt_as</code> <code>1</code> Human / GRCh38 no-alt analysis set, NCBI source1 <code>GRCm39</code> <code>1</code> Mouse / GRCm39, NCBI source1 <p>1These database indexes were generated by the Langmead Lab at Johns Hopkins and can be found on the lab's database index page.</p>"},{"location":"tool-reference/aligners/bowtie-2/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li><code>-3</code></li> <li><code>-5</code></li> <li><code>-a</code></li> <li><code>--align-paired-reads</code></li> <li><code>-D</code></li> <li><code>--dovetail</code></li> <li><code>--dpad</code></li> <li><code>--end-to-end</code></li> <li><code>-f</code></li> <li><code>-F</code></li> <li><code>--fast</code></li> <li><code>--fast-local</code></li> <li><code>--ff</code></li> <li><code>--fr</code></li> <li><code>--gbar</code></li> <li><code>-i</code></li> <li><code>-I</code></li> <li><code>--ignore-quals</code></li> <li><code>--int-quals</code></li> <li><code>-k</code></li> <li><code>-L</code></li> <li><code>--local</code></li> <li><code>--ma</code></li> <li><code>--maxins</code></li> <li><code>--minins</code></li> <li><code>--mp</code></li> <li><code>-N</code></li> <li><code>--n-ceil</code></li> <li><code>--no-1mm-upfront</code></li> <li><code>--no-contain</code></li> <li><code>--no-discordant</code></li> <li><code>--nofw</code></li> <li><code>--no-hd</code></li> <li><code>--no-mixed</code></li> <li><code>--non-deterministic</code></li> <li><code>--no-overlap</code></li> <li><code>--norc</code></li> <li><code>--no-sq</code></li> <li><code>--no-unal</code></li> <li><code>--np</code></li> <li><code>--omit-sec-seq</code></li> <li><code>--phred33</code></li> <li><code>--phred64</code></li> <li><code>--preserve-tags</code></li> <li><code>-q</code></li> <li><code>--qc-filter</code></li> <li><code>--qseq</code></li> <li><code>-r</code></li> <li><code>-R</code></li> <li><code>--rdg</code></li> <li><code>--rf</code></li> <li><code>--rfg</code></li> <li><code>--rg</code></li> <li><code>--rg-id</code></li> <li><code>-s</code></li> <li><code>--sam-append-comment</code></li> <li><code>--sam-no-qname-trunc</code></li> <li><code>--score-min</code></li> <li><code>--seed</code></li> <li><code>--sensitive</code></li> <li><code>--sensitive-local</code></li> <li><code>--soft-clipped-unmapped-tlen</code></li> <li><code>--solexa-quals</code></li> <li><code>-t</code></li> <li><code>--tab5</code></li> <li><code>--tab6</code></li> <li><code>--time</code></li> <li><code>--trim-to</code></li> <li><code>-u</code></li> <li><code>--very-fast</code></li> <li><code>--very-fast-local</code></li> <li><code>--very-sensitive</code></li> <li><code>--very-sensitive-local</code></li> <li><code>-X</code></li> <li><code>--xeq</code></li> </ul> <p>Additional arguments can be specified under the <code>tool_args</code> argument.</p>"},{"location":"tool-reference/aligners/clustal-omega/","title":"Clustal Omega","text":"<p>Clustal Omega is a fast and scalable tool that makes multiple sequence alignments of protein sequences. For more  information, see the tool's homepage.</p>"},{"location":"tool-reference/aligners/clustal-omega/#function-call","title":"Function Call","text":"<pre><code>tc.clustalo(\n    inputs,\n    output_path=None,\n    tool_args=\"\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/aligners/clustal-omega/#function-arguments","title":"Function Arguments","text":"<p>See the Notes section below for more details.</p> Argument Use in place of: Description <code>inputs</code> <code>-i</code> Path to one or more files to use as input. The files can be a local or remote, see Using Files. <code>output_path</code> <code>-o</code> (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to Clustal Omega. This should be a string of arguments like the command line. See Supported Additional Arguments for more details. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more."},{"location":"tool-reference/aligners/clustal-omega/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 1.2.4 of Clustal Omega.</p>"},{"location":"tool-reference/aligners/clustal-omega/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li><code>--auto</code></li> <li><code>--dealign</code></li> <li><code>--infmt</code></li> <li><code>--is-profile</code></li> <li><code>--iter</code></li> <li><code>--iterations</code></li> <li><code>--max-guidetree-iterations</code></li> <li><code>--max-hmm-iterations</code></li> <li><code>--maxnumseq</code></li> <li><code>--maxseqlen</code></li> <li><code>--outfmt</code></li> <li><code>--output-order</code></li> <li><code>--residuenumber</code></li> <li><code>--resno</code></li> <li><code>--seqtype</code></li> <li><code>-t</code></li> <li><code>--wrap</code></li> </ul> <p>Additional arguments can be specified under the <code>tool_args</code> argument.</p>"},{"location":"tool-reference/aligners/diamond/","title":"About DIAMOND","text":"<p>DIAMOND is an aligner for protein and translated DNA sequences. For more information, see the tool's  GitHub repo and wiki.</p> <p>DIAMOND has two modes available with Toolchest: BLASTP (<code>diamond blastp</code>) and BLASTX (<code>diamond blastx</code>).  Each mode has its own function call (<code>diamond_blastp</code> and <code>diamond_blastx</code>, respectively). See the relevant subpage for  in-depth documentation:</p> <ul> <li>DIAMOND BLASTP</li> <li>DIAMOND BLASTX</li> </ul>"},{"location":"tool-reference/aligners/kallisto/","title":"Kallisto","text":"<p>Kalisto is a program for quantifying abundances of transcripts from RNA-Seq data. For more information, see the  tool's GitHub repo. Toolchest only supports running <code>kallisto quant</code> with  pre-built indexes at this time.</p>"},{"location":"tool-reference/aligners/kallisto/#function-call","title":"Function Call","text":"<pre><code>tc.kallisto(\n    inputs=[]\n    output_path=None,\n    tool_args=\"\",\n    database_name=\"kallisto_homo_sapiens\",\n    database_version=\"1\",\n    gtf=None, \n    chromosomes=None,\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/aligners/kallisto/#function-arguments","title":"Function Arguments","text":"Argument Use in place of: Description <code>inputs</code> Path or list of paths to input files for the Kallisto run. The files can be local or remote, see Using Files. <code>output_path</code> output file location (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be local or remote, see Using Files. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to Kallisto. This should be a string of arguments like the command line. <code>database_name</code> <code>-i</code>, <code>--index</code> (optional) Name of database to use for Kallisto alignment. Defaults to <code>\"kallisto_homo_sapiens\"</code>. <code>database_version</code> <code>-i</code>, <code>--index</code> (optional) Version of database to use for Kallisto alignment. Defaults to <code>\"1\"</code>. <code>gtf</code> <code>-g</code>, <code>--gtf</code> (optional) path to a GTF file for transcriptome information (required when using <code>--genomebam</code> tool arg). See the Kallisto manual for more info. <code>chromosomes</code> <code>-c</code>, <code>--chromosomes</code> (optional) Path to a tab separated file with chromosome names and lengths (recommended when using <code>--genomebam</code> tool arg). See the Kallisto manual for more info. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>See the Databases section for more details.</p>"},{"location":"tool-reference/aligners/kallisto/#notes","title":"Notes","text":""},{"location":"tool-reference/aligners/kallisto/#single-end-inputs","title":"Single-end inputs","text":"<p>Single-end read inputs require <code>--single</code>, <code>--fragment-length</code> (or <code>-l</code>), and <code>--sd</code> (or <code>-s</code>) to be provided via  <code>tool_args</code>. See the Kallisto manual for more info.</p>"},{"location":"tool-reference/aligners/kallisto/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 0.48.0 of Kallisto.</p>"},{"location":"tool-reference/aligners/kallisto/#databases","title":"Databases","text":"<p>Toolchest currently supports the following databases for Kallisto:</p> <code>database_name</code> <code>database_version</code> Description <code>kallisto_homo_sapiens</code> <code>1</code> Homo sapiens Ensembl v96 index for Kallisto, pulled from https://github.com/pachterlab/kallisto-transcriptome-indices/releases/tag/ensembl-96. <code>kallisto_caenorhabditis_elegans</code> <code>1</code> Caenorhabditis elegans Ensembl v96 index for Kallisto, pulled from https://github.com/pachterlab/kallisto-transcriptome-indices/releases/tag/ensembl-96. <code>kallisto_danio_rerio</code> <code>1</code> Danio rerio Ensembl v96 index for Kallisto, pulled from https://github.com/pachterlab/kallisto-transcriptome-indices/releases/tag/ensembl-96. <code>kallisto_drosophila_melanogaster</code> <code>1</code> Drosophila melanogaster Ensembl v96 index for Kallisto, pulled from https://github.com/pachterlab/kallisto-transcriptome-indices/releases/tag/ensembl-96. <code>kallisto_gallus_gallus</code> <code>1</code> Gallus gallus Ensembl v96 index for Kallisto, pulled from https://github.com/pachterlab/kallisto-transcriptome-indices/releases/tag/ensembl-96. <code>kallisto_mus_musculus</code> <code>1</code> Mus Musculus Ensembl v96 index for Kallisto, pulled from https://github.com/pachterlab/kallisto-transcriptome-indices/releases/tag/ensembl-96. <code>kallisto_pan_troglodytes</code> <code>1</code> Pan Troglodytes Ensembl v96 index for Kallisto, pulled from https://github.com/pachterlab/kallisto-transcriptome-indices/releases/tag/ensembl-96. <code>kallisto_rattus_norvegicus</code> <code>1</code> Rattus norvegicus Ensembl v96 index for Kallisto, pulled from https://github.com/pachterlab/kallisto-transcriptome-indices/releases/tag/ensembl-96. <code>kallisto_saccharomyces_cerevisiae</code> <code>1</code> Saccharomyces cerevisiae Ensembl v96 index for Kallisto, pulled from https://github.com/pachterlab/kallisto-transcriptome-indices/releases/tag/ensembl-96. <code>kallisto_xenopus_tropicalis</code> <code>1</code> Xenopus tropicalis Ensembl v96 index for Kallisto, pulled from https://github.com/pachterlab/kallisto-transcriptome-indices/releases/tag/ensembl-96."},{"location":"tool-reference/aligners/kallisto/#other-modes","title":"Other modes","text":"<p>Only <code>quant</code> mode is supported at this time.</p>"},{"location":"tool-reference/aligners/rapsearch2/","title":"RAPSearch2","text":"<p>RAPSearch2 is an aligner for protein similarity searches. It aligns DNA reads or protein sequences against a  protein database. For more information, see the tool's homepage , GitHub repo, and Sourceforge page.</p>"},{"location":"tool-reference/aligners/rapsearch2/#function-call","title":"Function Call","text":"<pre><code>tc.rapsearch2(\n    inputs,\n    output_path=None,\n    database_name=\"rapsearch2_seqscreen\",\n    database_version=\"1\",\n    tool_args=\"\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/aligners/rapsearch2/#function-arguments","title":"Function Arguments","text":"<p>See the Notes section below for more details.</p> Argument Use in place of: Description <code>inputs</code> <code>-q</code> Path to one or more files to use as input. The files can be a local or remote, see Using Files. <code>output_path</code> <code>-o</code> (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>database_name</code> <code>-d</code>* (optional) Name of database to use for RAPSearch2 alignment. Defaults to <code>\"GRCh38\"</code> (human genome). <code>database_version</code> <code>-d</code>* (optional) Version of database to use for RAPSearch2 alignment. Defaults to <code>\"1\"</code>. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to RAPSearch2. This should be a string of arguments like the command line. See Supported Additional Arguments for more details. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>*See the Databases section for more details.</p>"},{"location":"tool-reference/aligners/rapsearch2/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 2.24 of RAPSearch2.</p>"},{"location":"tool-reference/aligners/rapsearch2/#databases","title":"Databases","text":"<p>Toolchest currently supports the following databases for RAPSearch2:</p> <code>database_name</code> <code>database_version</code> Description <code>rapsearch_seqscreen</code> <code>1</code> SeqScreen RAPSearch2 Database. See the SeqScreen wiki for more details."},{"location":"tool-reference/aligners/rapsearch2/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li><code>-a</code></li> <li><code>-b</code></li> <li><code>-e</code></li> <li><code>-g</code></li> <li><code>-i</code></li> <li><code>-l</code></li> <li><code>-p</code></li> <li><code>-s</code></li> <li><code>-t</code></li> <li><code>-v</code></li> <li><code>-w</code></li> <li><code>-x</code></li> </ul> <p>Additional arguments can be specified under the <code>tool_args</code> argument.</p>"},{"location":"tool-reference/aligners/salmon/","title":"Salmon","text":"<p>Salmon is a computational genomics tool for transcriptomic analysis. For more information, see the tool's  GitHub repo. Toolchest only supports running <code>salmon quant</code> with pre-built  indexes in mapping mode at this time.</p>"},{"location":"tool-reference/aligners/salmon/#function-call","title":"Function Call","text":"<pre><code>tc.salmon(\n    read_one=None,\n    read_two=None,\n    single_end=None,\n    output_path=None,\n    tool_args=\"\",\n    database_name=\"salmon_hg38\",\n    database_version=\"1\",\n    library_type=\"A\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/aligners/salmon/#function-arguments","title":"Function Arguments","text":"Argument Use in place of: Description <code>read_one</code> <code>-1</code> (optional) Path or list of paths to R1 of paired-end read input files. The files can be a local or remote, see Using Files. <code>read_two</code> <code>-2</code> (optional) Path or list of paths to R2 of paired-end read input files. The files can be a local or remote, see Using Files. <code>single_end</code> <code>-r</code> (optional) Path or list of paths to of single-end (or just R1 or R2) read input files. The files can be a local or remote, see Using Files. <code>output_path</code> output file location (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to Salmon. This should be a string of arguments like the command line. <code>database_name</code> <code>-i</code> (optional) Name of database to use for Kraken 2 alignment. Defaults to <code>\"salmon_hg38\"</code>. <code>database_version</code> <code>-i</code> (optional) Version of database to use for Kraken 2 alignment. Defaults to <code>\"1\"</code>. <code>library_type</code> <code>-l</code>, <code>--libType</code> (optional) The library type used. Defaults to \"A\" for automatic classification. See the Salmon docs on library types for more. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>See the Databases section for more details.</p>"},{"location":"tool-reference/aligners/salmon/#notes","title":"Notes","text":""},{"location":"tool-reference/aligners/salmon/#paired-end-inputs","title":"Paired-end inputs","text":"<p>Paired-end read inputs can be set with either <code>inputs</code> or through <code>read_one</code> and <code>read_two</code>.</p> <p>Make sure that the first item in <code>read_one</code> corresponds to the first item in <code>read_two</code>\u2013 and so on.</p> <p>If you only have one end of a paired-end run, use the <code>single_end</code> argument.</p>"},{"location":"tool-reference/aligners/salmon/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 1.9.0 of Salmon.</p>"},{"location":"tool-reference/aligners/salmon/#databases","title":"Databases","text":"<p>Toolchest currently supports the following databases for Salmon:</p> <code>database_name</code> <code>database_version</code> Description <code>hg38</code> <code>1</code> hg38 precomputed index for Salmon, pulled from http://refgenomes.databio.org/."},{"location":"tool-reference/aligners/salmon/#other-modes","title":"Other modes","text":"<p>Only <code>quant</code> mode is supported at this time.</p>"},{"location":"tool-reference/aligners/star/","title":"STAR","text":"<p>STAR is an aligner for RNA sequencing. It rapidly aligns RNA-seq reads against a genome index. For more information, see the tool's GitHub repo and manual.</p>"},{"location":"tool-reference/aligners/star/#function-call","title":"Function Call","text":"<pre><code>tc.STAR(\n    read_one,\n    read_two=None,\n    output_path=None,\n    tool_args=\"\",\n    database_name=\"GRCh38\",\n    database_version=\"1\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/aligners/star/#function-arguments","title":"Function Arguments","text":"<p>See the Notes section below for more details.</p> Argument Use in place of: Description <code>read_one</code> <code>--readFilesIn</code> Paths to single-end read input file, or R1 of paired-end read input files. The files can be a local or remote, see Using Files. <code>read_two</code> <code>--readFilesIn</code> (optional) Path to read 2 of paired-end read input files. This can be a local filepath or an AWS S3 URI. <code>output_path</code> <code>--outFileNamePrefix</code> (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to STAR. This should be a string of arguments like the command line. See Supported Additional Arguments for more details. <code>database_name</code> <code>--genomeDir</code>* (optional) Name of database to use for STAR alignment. Defaults to <code>\"GRCh38\"</code> (human genome). <code>database_version</code> <code>--genomeDir</code>* (optional) Version of database to use for STAR alignment. Defaults to <code>\"1\"</code>. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>See the Databases section for more details.</p>"},{"location":"tool-reference/aligners/star/#notes","title":"Notes","text":""},{"location":"tool-reference/aligners/star/#single-end-and-paired-end-inputs","title":"Single-end and paired-end inputs","text":"<p>Paired-end read inputs should be specified with both <code>read_one</code> and <code>read_two</code>.</p> <p>For single-end read inputs, specify the input as <code>read_one</code> argument and omit <code>read_two</code>.</p>"},{"location":"tool-reference/aligners/star/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 2.7.9a of STAR. Every request to run STAR with Toolchest will default to this version.</p>"},{"location":"tool-reference/aligners/star/#databases","title":"Databases","text":"<p>Toolchest currently supports the following databases for STAR:</p> <code>database_name</code> <code>database_version</code> Description <code>GRCh38</code> <code>1</code> GRCh38 (human) genome, built from patch GRCh38.p13 using STAR 2.7.4a"},{"location":"tool-reference/aligners/star/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li><code>--alignEndsProtrude</code></li> <li><code>--alignEndsType</code></li> <li><code>--alignInsertionFlush</code></li> <li><code>--alignIntronMax</code></li> <li><code>--alignIntronMin</code></li> <li><code>--alignMatesGapMax</code></li> <li><code>--alignSJDBoverhangMin</code></li> <li><code>--alignSJoverhangMin</code></li> <li><code>--alignSJstitchMismatchNmax</code></li> <li><code>--alignSoftClipAtReferenceEnds</code></li> <li><code>--alignSplicedMateMapLmin</code></li> <li><code>--alignSplicedMateMapLminOverLmate</code></li> <li><code>--alignTranscriptsPerReadNmax</code></li> <li><code>--alignTranscriptsPerWindowNmax</code></li> <li><code>--alignWindowsPerReadNmax</code></li> <li><code>--outFilterMatchNmin</code></li> <li><code>--outFilterMismatchNmax</code></li> <li><code>--outFilterMismatchNoverReadLmax</code></li> <li><code>--outFilterMultimapNmax</code></li> <li><code>--outFilterType</code></li> <li><code>--outReadsUnmapped</code></li> <li><code>--outSAMstrandField</code></li> <li><code>--outSAMtype</code></li> <li><code>--quantMode</code></li> <li><code>--quantTranscriptomeBAMcompression</code></li> <li><code>--quantTranscriptomeBan</code></li> <li><code>--readFilesCommand</code></li> <li><code>--readFilesType</code></li> <li><code>--readMapNumber</code></li> <li><code>--readMatesLengthsIn</code></li> <li><code>--readStrand</code></li> <li><code>--runRNGseed</code></li> <li><code>--scoreDelBase</code></li> <li><code>--scoreDelOpen</code></li> <li><code>--scoreGap</code></li> <li><code>--scoreGapATAC</code></li> <li><code>--scoreGapGCAG</code></li> <li><code>--scoreGapNoncan</code></li> <li><code>--scoreGenomicLengthLog2scale</code></li> <li><code>--scoreInsBase</code></li> <li><code>--scoreInsOpen</code></li> <li><code>--scoreStitchSJshift</code></li> <li><code>--seedMultimapNmax</code></li> <li><code>--seedNoneLociPerWindow</code></li> <li><code>--seedPerReadNmax</code></li> <li><code>--seedPerWindowNmax</code></li> <li><code>--seedSearchLmax</code></li> <li><code>--seedSearchStartLmax</code></li> <li><code>--seedSearchStartLmaxOverLread</code></li> <li><code>--seedSplitMin</code></li> <li><code>--sjdbInsertSave</code></li> <li><code>--twopassMode</code></li> <li><code>--winAnchorDistNbins</code></li> <li><code>--winAnchorMultimapNmax</code></li> <li><code>--winBinNbits</code></li> <li><code>--winFlankNbins</code></li> <li><code>--winReadCoverageBasesMin</code></li> <li><code>--winReadCoverageRelativeMin</code></li> </ul> <p>Additional arguments can be specified under the <code>tool_args</code> argument.</p>"},{"location":"tool-reference/aligners/diamond/diamond-blastp/","title":"DIAMOND BLASTP","text":"<p>DIAMOND BLASTP is DIAMOND's mode for protein sequence searches. For more information, see the tool's GitHub repo and wiki.</p>"},{"location":"tool-reference/aligners/diamond/diamond-blastp/#function-call","title":"Function Call","text":"<pre><code>tc.diamond_blastp(\n    inputs,\n    output_path=None,\n    database_name=\"diamond_blastp_standard\",\n    database_version=\"1\",\n    remote_database_path=None,\n    remote_database_primary_name=None,\n    tool_args=\"\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/aligners/diamond/diamond-blastp/#function-arguments","title":"Function Arguments","text":"<p>See the Notes section below for more details.</p> Argument Use in place of: Description <code>inputs</code> <code>-q</code>, <code>--query</code> Path to one or more files to use as input. FASTA or FASTQ formats are supported, as well as gzip-compressed FASTA/FASTQ files. The files can be a local or remote, see Using Files. <code>output_path</code> <code>-o</code>, <code>--out</code> (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>database_name</code> <code>-d</code> (optional) Name of database to use for DIAMOND BLASTP. Defaults to <code>\"diamond_blastp_standard\"</code>, the SeqScreen database. <code>database_version</code> database version (optional) Version of database to use for DIAMOND BLASTP. Defaults to <code>\"1\"</code>. <code>remote_database_path</code> <code>-d</code> (path) (optional) AWS S3 URI to the directory that contains your custom database. <code>remote_database_primary_name</code> <code>-d</code> (name) (optional) The primary name (e.g. UNIREF100.mini) of your custom database. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to Diamond BLASTp. This should be a string of arguments like the command line. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>DIAMOND BLASTP runs are aligned against the SeqScreen database by default. See the Databases section for more details.</p>"},{"location":"tool-reference/aligners/diamond/diamond-blastp/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 2.0.14 of DIAMOND.</p>"},{"location":"tool-reference/aligners/diamond/diamond-blastp/#databases","title":"Databases","text":"<p>Toolchest currently supports the following databases for DIAMOND BLASTP:</p> <code>database_name</code> <code>database_version</code> Description <code>diamond_blastp_standard</code> <code>1</code> SeqScreen DIAMOND BLASTP Database. See the SeqScreen wiki for more details."},{"location":"tool-reference/aligners/diamond/diamond-blastp/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li><code>-f</code></li> <li><code>--fast</code></li> <li><code>-l</code></li> <li><code>--mid-sensitive</code></li> <li><code>--min-orf</code></li> <li><code>--more-sensitive</code></li> <li><code>--no-self-hits</code></li> <li><code>--outfmt</code></li> <li><code>--sallseqid</code></li> <li><code>--salltitles</code></li> <li><code>--sensitive</code></li> <li><code>--strand</code></li> <li><code>--ultra-sensitive</code></li> <li><code>--unal</code></li> <li><code>--very-sensitive</code></li> </ul> <p>Additional arguments can be specified under the <code>tool_args</code> argument.</p>"},{"location":"tool-reference/aligners/diamond/diamond-blastx/","title":"DIAMOND BLASTX","text":"<p>DIAMOND BLASTX is DIAMOND's mode for translated DNA sequence searches. For more information, see the tool's GitHub repo and wiki.</p>"},{"location":"tool-reference/aligners/diamond/diamond-blastx/#function-call","title":"Function Call","text":"<pre><code>tc.diamond_blastx(\n    inputs,\n    output_path=None,\n    database_name=\"diamond_blastx_standard\",\n    database_version=\"1\",\n    remote_database_path=None,\n    remote_database_primary_name=None,\n    tool_args=\"\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/aligners/diamond/diamond-blastx/#function-arguments","title":"Function Arguments","text":"<p>See the Notes section below for more details.</p> Argument Use in place of: Description <code>inputs</code> <code>-q</code>, <code>--query</code> Path to one or more files to use as input. FASTA or FASTQ formats are supported, as well as gzip-compressed FASTA/FASTQ files. The files can be a local or remote, see Using Files. <code>output_path</code> <code>-o</code>, <code>--out</code> (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>database_name</code> <code>-d</code> (optional) Name of database to use for DIAMOND BLASTX. Defaults to <code>\"diamond_blastx_standard\"</code>, the SeqScreen database. <code>database_version</code> database version (optional) Version of database to use for DIAMOND BLASTX. Defaults to <code>\"1\"</code>. <code>remote_database_path</code> <code>-d</code> (path) (optional) AWS S3 URI to the directory that contains your custom database. <code>remote_database_primary_name</code> <code>-d</code> (name) (optional) The primary name (e.g. UNIREF100.mini) of your custom database. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to Diamond BLASTX. This should be a string of arguments like the command line. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>DIAMOND BLASTX runs are aligned against the SeqScreen database by default. See the Databases section for more details.</p>"},{"location":"tool-reference/aligners/diamond/diamond-blastx/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 2.0.14 of DIAMOND. Every request to run DIAMOND BLASTX with Toolchest will default to this version.</p>"},{"location":"tool-reference/aligners/diamond/diamond-blastx/#databases","title":"Databases","text":"<p>Toolchest currently supports the following databases for DIAMOND BLASTX:</p> <code>database_name</code> <code>database_version</code> Description <code>diamond_blastx_standard</code> <code>1</code> SeqScreen DIAMOND BLASTX Database. See the SeqScreen wiki for more details."},{"location":"tool-reference/aligners/diamond/diamond-blastx/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li><code>-e</code></li> <li><code>--evalue</code></li> <li><code>-f</code></li> <li><code>-l</code></li> <li><code>--masking</code></li> <li><code>--min-orf</code></li> <li><code>--no-self-hits</code></li> <li><code>--outfmt</code></li> <li><code>--sallseqid</code></li> <li><code>--salltitles</code></li> <li><code>--strand</code></li> <li><code>--top</code></li> <li><code>--unal</code></li> </ul> <p>Additional arguments can be specified under the <code>tool_args</code> argument.</p>"},{"location":"tool-reference/assemblers/megahit/","title":"MEGAHIT","text":"<p>MEGAHIT is an assembler that's optimized for metagenomes. For more information, see the tool's  GitHub repo and wiki.</p>"},{"location":"tool-reference/assemblers/megahit/#function-call","title":"Function Call","text":"<pre><code>tc.megahit(\n    read_one=None,\n    read_two=None,\n    interleaved=None,\n    single_end=None,\n    output_path=None,\n    tool_args=\"\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/assemblers/megahit/#function-arguments","title":"Function Arguments","text":"<p>See the Notes section below for more details.</p> Argument Use in place of: Description <code>read_one</code> <code>-1</code> (optional) Path to R1 of paired-end short read input files. The file can be a local or remote, see Using Files. <code>read_two</code> <code>-2</code> (optional) Path to R2 of paired-end short read input files. The file can be a local or remote, see Using Files. <code>interleaved</code> <code>--12</code> (optional) Path to the file containing interleaved reads. The file can be a local or remote, see Using Files. <code>single_end</code> <code>-r</code> (optional) Path to the file containing singled-ended reads. The file can be a local or remote, see Using Files. <code>output_path</code> <code>-o</code> (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>tool_args</code> all other arguments (optional) A string containing additional arguments to be passed to MEGAHIT, formatted as if using the command line. <code>is_async</code> Whether to run a job asynchronously. See Async Runs for more."},{"location":"tool-reference/assemblers/megahit/#notes","title":"Notes","text":""},{"location":"tool-reference/assemblers/megahit/#paired-end-reads","title":"Paired-end reads","text":"<p>For each paired-end input, make sure the corresponding read is in the same position in the input list. For example, two  pairs of paired-end files \u2013 <code>one_R1.fastq</code>, <code>one_R2.fastq</code>, <code>two_R1.fastq</code>, <code>two_R2.fastq</code> \u2013 should be passed to  Toolchest as:</p> <pre><code>tc.megahit(\n  read_one=[\"one_R1.fastq\", \"two_R1.fastq\"],\n  read_two=[\"one_R2.fastq\", \"two_R2.fastq\"],\n  ...\n)\n</code></pre>"},{"location":"tool-reference/assemblers/megahit/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 1.2.9 of MEGAHIT. </p>"},{"location":"tool-reference/assemblers/megahit/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li>--min-count</li> <li>--k-list</li> <li>--k-min</li> <li>--k-max</li> <li>--k-step</li> <li>--no-mercy</li> <li>--bubble-level</li> <li>--merge-level</li> <li>--prune-level</li> <li>--prune-depth</li> <li>--disconnect-ratio</li> <li>--low-local-ratio</li> <li>--max-tip-len</li> <li>--cleaning-rounds</li> <li>--no-local</li> <li>--kmin-1pass</li> <li>--presets</li> <li>--min-contig-len</li> </ul> <p>Set additional arguments with <code>tool_args</code>. For example: <code>tool_args=\"--no-local --no-mercy\"</code></p>"},{"location":"tool-reference/assemblers/unicycler/","title":"Unicycler","text":"<p>Unicycler is an assembly pipeline for bacterial genomes. For more information, see the tool's  GitHub repo and wiki.</p>"},{"location":"tool-reference/assemblers/unicycler/#function-call","title":"Function Call","text":"<pre><code>tc.unicycler(\n    read_one=None,\n    read_two=None,\n    long_reads=None,\n    output_path=None,\n    tool_args=\"\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/assemblers/unicycler/#function-arguments","title":"Function Arguments","text":"Argument Use in place of: Description <code>read_one</code> <code>-1</code> (optional) Path to R1 of paired-end short read input files. The file can be a local or remote, see Using Files. <code>read_two</code> <code>-2</code> (optional) Path to R2 of paired-end short read input files. The file can be a local or remote, see Using Files. <code>long_reads</code> <code>-l</code> (optional) Path to the file containing long reads. The file can be a local or remote, see Using Files. <code>output_path</code> <code>-o</code> (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to Unicycler. This should be a string of arguments like the command line. See Supported Additional Arguments for more details. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more."},{"location":"tool-reference/assemblers/unicycler/#notes","title":"Notes","text":""},{"location":"tool-reference/assemblers/unicycler/#paired-end-reads","title":"Paired-end reads","text":"<p>Paired-end short read inputs should be specified with both <code>read_one</code> and <code>read_two</code>.</p>"},{"location":"tool-reference/assemblers/unicycler/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 0.4.9 of Unicycler. </p>"},{"location":"tool-reference/assemblers/unicycler/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li><code>--depth_filter</code></li> <li><code>--kmer_count</code></li> <li><code>--kmers</code></li> <li><code>--largest_component</code></li> <li><code>--linear_seqs</code></li> <li><code>--low_score</code></li> <li><code>--max_kmer_frac</code></li> <li><code>--min_component_size</code></li> <li><code>--min_dead_end_size</code></li> <li><code>--min_fasta_length</code></li> <li><code>--min_kmer_frac</code></li> <li><code>--min_polish_size</code></li> <li><code>--mode</code></li> <li><code>--no_correct</code></li> <li><code>--no_miniasm</code></li> <li><code>--no_pilon</code></li> <li><code>--no_rotate</code></li> <li><code>--scores</code></li> <li><code>--start_gene_cov</code></li> <li><code>--start_gene_id</code></li> <li><code>--verbosity</code></li> </ul> <p>Additional arguments can be specified under the <code>tool_args</code> argument.</p>"},{"location":"tool-reference/demultiplexers/demucs/","title":"DEMUCS","text":"<p>demucs is a demultiplexing tool for audio source separation. To learn more about the tool, check out its  GitHub repo.</p>"},{"location":"tool-reference/demultiplexers/demucs/#function-call","title":"Function Call","text":"<pre><code>tc.demucs(\n    inputs,\n    output_path=None,\n    tool_args=\"\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/demultiplexers/demucs/#function-arguments","title":"Function Arguments","text":"<p>See the Notes section below for more details.</p> Argument Use in place of: Description <code>inputs</code> <code>--input</code> Path to a file that will be passed in as input. All formats supported by <code>ffmpeg</code> are allowed. The files can be a local or remote, see Using Files. <code>output_path</code> <code>--output</code> (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>tool_args</code> all other arguments (optional) A string containing additional arguments to be passed to Demucs, formatted as if using the command line. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more."},{"location":"tool-reference/demultiplexers/demucs/#tool-versions","title":"Tool Versions","text":"<p>Toolchest supports version 3.0.4 of Demucs.</p>"},{"location":"tool-reference/demultiplexers/demucs/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li>-v</li> <li>--verbose</li> <li>--shifts</li> <li>--overlap</li> <li>-no-split</li> <li>--two-stems</li> <li>--int24</li> <li>--float32</li> <li>--clip-mode</li> <li>--mp3</li> <li>--mp3-bitrate</li> <li>-n</li> </ul> <p>Set additional arguments with <code>tool_args</code>. For example: <code>tool_args=\"-n mdx_extra --shifts=5\"</code></p>"},{"location":"tool-reference/post-processing/bracken/","title":"Bracken","text":"<p>Bracken estimates abundance at a given taxonomic level using the output report from Kraken 2. See the  Bracken GitHub repo for more.</p>"},{"location":"tool-reference/post-processing/bracken/#function-call","title":"Function Call","text":"<pre><code>tc.bracken(\n    kraken2_report,\n    output_path=None,\n    output_primary_name=\"output.bracken\",\n    tool_args=\"\",\n    database_name=\"standard\",\n    database_version=\"1\",\n    remote_database_path=None,\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/post-processing/bracken/#function-arguments","title":"Function Arguments","text":"Argument Use in place of: Description <code>kraken2_report</code> Kraken 2 report file input Path to Kraken 2 report file. The files can be a local or remote, see Using Files. <code>output_path</code> <code>-o</code> directory name (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>output_primary_name</code> <code>-o</code> file name (Optional) Name of Bracken output file. Defaults to <code>\"output.bracken\"</code>. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to Bracken. This should be a string of arguments like the command line. See Supported Additional Arguments for more details. <code>database_name</code> <code>-d</code> (optional) Name of database that was used for Kraken 2 alignment. Defaults to <code>\"standard\"</code>. <code>database_version</code> <code>-d</code> (optional) Version of database that was used for Kraken 2 alignment. Defaults to <code>\"1\"</code>. <code>remote_database_path</code> <code>-d</code> (optional) AWS S3 URI to a directory with your custom database that was used with Kraken 2 alignment. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>See the Databases section for more details.</p>"},{"location":"tool-reference/post-processing/bracken/#output-files","title":"Output Files","text":"<p>A Bracken run will output one file into <code>output_path</code>:</p> <ul> <li><code>output.bracken</code>: Bracken report. You can change this name with the <code>output_primary_name</code> Toolchest argument.</li> </ul>"},{"location":"tool-reference/post-processing/bracken/#notes","title":"Notes","text":""},{"location":"tool-reference/post-processing/bracken/#custom-database-arguments","title":"Custom database arguments","text":"<p>If using <code>custom_database_path</code>, the given database will take priority over any database selected via <code>database_name</code> and <code>database_version</code>.</p>"},{"location":"tool-reference/post-processing/bracken/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 2.7 of Bracken.</p>"},{"location":"tool-reference/post-processing/bracken/#databases","title":"Databases","text":"<p>Toolchest currently supports the following databases for Bracken 2:</p> <code>database_name</code> <code>database_version</code> Description <code>standard</code> <code>1</code> RefSeq archaea, bacteria, viral, plasmid, human1, UniVec_Core1 <code>refseq_fungi</code> <code>20211120</code> RefSeq fungi, generated on 11/20/2021 <p>1This database index was generated by the Langmead Lab at Johns Hopkins and can be found on the lab's database index page.</p>"},{"location":"tool-reference/post-processing/bracken/#custom-databases","title":"Custom Databases","text":"<p>Toolchest supports custom databases hosted in S3, so long as they are accessible from Toolchest. Use the argument  <code>custom_database_path</code> to set the S3 URI of the folder with the database index files.</p>"},{"location":"tool-reference/post-processing/bracken/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li><code>-r</code> (read length)</li> <li><code>-l</code> (taxonomic level)</li> <li><code>-t</code> (threshold)</li> </ul> <p>These and any additional arguments are set with the <code>tool_args</code> Toolchest argument.</p>"},{"location":"tool-reference/pre-processing/fastqc/","title":"FastQC","text":"<p>FastQC is a quality control tool for genomic sequence data. See their website for more details.</p>"},{"location":"tool-reference/pre-processing/fastqc/#function-call","title":"Function Call","text":"<pre><code>tc.fastqc(\n    inputs,\n    output_path=None,\n    contaminants=None,\n    adapters=None,\n    limits=None,\n    tool_args=\"\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/pre-processing/fastqc/#function-arguments","title":"Function Arguments","text":"Argument Use in place of: Description <code>inputs</code> input file location Path to one or more files to use as input.  \\nSAM, BAM, or FASTQ formats are supported, as well as gzip-compressed variants. The files can be a local or remote, see Using Files. <code>output_path</code> <code>-o</code> (directory name) (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>contaminants</code> <code>-c</code> or <code>--contaminants</code> file path. (optional) Path to a custom contaminants file. <code>adapters</code> <code>-a</code> or <code>--adapters</code> file path. (optional) Path to a custom adapters file. <code>limits</code> <code>-l</code> or <code>--limits</code> file path (optional) Path to a custom limits file. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to FastQC. This should be a string of arguments like the command line. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more."},{"location":"tool-reference/pre-processing/fastqc/#output-files","title":"Output Files","text":"<p>A FastQC run will output the html report and output zip into <code>output_path</code>:</p> <ul> <li><code>{input file name}_fastqc.html</code>: FastQC HTML report for checking data quality</li> <li><code>{input file name}\\_fastqc.zip</code>: Zip directory containing the HTML report and some supporting files</li> </ul>"},{"location":"tool-reference/pre-processing/fastqc/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 0.11.9 of FastQC.</p>"},{"location":"tool-reference/structure-prediction/alphafold/","title":"AlphaFold","text":"<p>AlphaFold is a deep learning tool for predicting a protein\u2019s 3D structure from its amino acid sequence. It was  developed by DeepMind and utilizes GPU compute. For more information, see the tool's  homepage and GitHub repo.</p>"},{"location":"tool-reference/structure-prediction/alphafold/#function-call","title":"Function Call","text":"<pre><code>tc.alphafold(\n    inputs,\n    output_path=None,\n    model_preset=None,\n    max_template_date=None,\n    use_reduced_dbs=False,\n    is_prokaryote_list=None,\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/structure-prediction/alphafold/#function-arguments","title":"Function Arguments","text":"<p>See the Notes section below for more details.</p> Argument Use in place of: Description <code>inputs</code> <code>--fasta-paths</code> Path to one or more files to use as input. The files can be a local or remote, see Using Files. <code>output_path</code> <code>--output_dir</code> (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>model_preset</code> <code>--model_preset</code> (optional) Specific AlphaFold model to use. Options are [<code>monomer</code>, <code>monomer_casp14</code>, <code>monomer_ptm</code>, <code>multimer</code>]. Defaults to <code>monomer</code>. <code>max_template_date</code> <code>--max_template_date</code> (optional) String of date in YYYY-MM-DD format.  Restricts protein structure prediction to those in the database before this date. Defaults to today's date. <code>use_reduced_dbs</code> <code>--db_preset=reduced_dbs</code> (optional) Whether to use a smaller version of the BFD database. If true, reduces run time at the cost of result quality. <code>is_prokaryote_list</code> <code>--is_prokaryote_list</code> (optional) List of booleans that determines whether all input sequences in the given FASTA file are prokaryotic. Expects the string normally used input into AlphaFold (e.g. \"true,true\" if there are two prokaryote inputs). <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more."},{"location":"tool-reference/structure-prediction/alphafold/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 2.1.2 of AlphaFold. </p>"},{"location":"tool-reference/structure-prediction/alphafold/#database","title":"Database","text":"<p>Toolchest's implementation of AlphaFold uses AlphaFold's required genetic sequence databases. For a complete list of databases used, see the tool's GitHub page.</p>"},{"location":"tool-reference/structure-prediction/alphafold/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<p>Toolchest supports the following arguments for AlphaFold: </p> <ul> <li><code>--db_preset</code></li> <li><code>--is_prokaryote_list</code></li> <li><code>--max_template_date</code></li> <li><code>--model_preset</code></li> </ul> <p>However, these should be specified via specific argument values in the function call, rather than through a generic <code>tool_args</code> argument (like other Toolchest tools). See Function Arguments for more details.</p>"},{"location":"tool-reference/taxonomic-classifiers/centrifuge/","title":"Centrifuge","text":"<p>Centrifuge is a rapid and memory-efficient classifier of DNA sequences from microbial samples. Centrifuge requires a relatively small genome index (e.g., 4.3 GB for ~4,100 bacterial genomes) and can process a  typical DNA sequencing run within an hour. For more information,  see the tool's website and  GitHub repo.</p>"},{"location":"tool-reference/taxonomic-classifiers/centrifuge/#function-call","title":"Function Call","text":"<pre><code>tc.centrifuge(\n    output_path=None,\n    tool_args=\"\",\n    database_name=\"centrifuge_refseq_bacteria_archaea_viral_human\",\n    database_version=\"1\",\n    read_one=None,\n    read_two=None,\n    unpaired=None,\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/taxonomic-classifiers/centrifuge/#function-arguments","title":"Function Arguments","text":"Argument Use in place of: Description <code>read_one</code> <code>-1</code> (optional) Path(s) to R1 of paired-end read input files. The files can be a local or remote, see Using Files. <code>read_two</code> <code>-2</code> (optional) Path(s) to R2 of paired-end read input files. The files can be a local or remote, see Using Files. <code>unpaired</code> <code>-U</code> (optional) Path(s) to unpaired input files. The files can be a local or remote, see Using Files. <code>output_path</code> output arguments (<code>-S</code>, <code>--report</code>) (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to Centrifuge. This should be a string of arguments like the command line. See Supported Additional Arguments for more details. <code>database_name</code> <code>-x</code>* (optional) Name of database to use for Centrifuge classification. Defaults to <code>\"centrifuge_refseq_bacteria_archaea_viral_human\"</code> (Refseq bacteria / archaea / viral / human). <code>database_version</code> <code>-x</code>* (optional) Version of database to use for Centrifuge classification. Defaults to <code>\"1\"</code>. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>*See the Databases section for more details.</p>"},{"location":"tool-reference/taxonomic-classifiers/centrifuge/#output-files","title":"Output Files","text":"<p>A Centrifuge run will output these files into  <code>output_path</code>:</p> <ul> <li><code>centrifuge_output.txt</code>: Centrifuge output (captured from <code>stdout</code>), from the <code>-S</code> argument.</li> <li><code>centrifuge_report.tsv</code>: Centrifuge report file, from the <code>--report</code> argument.</li> </ul>"},{"location":"tool-reference/taxonomic-classifiers/centrifuge/#notes","title":"Notes","text":""},{"location":"tool-reference/taxonomic-classifiers/centrifuge/#paired-end-reads","title":"Paired-end reads","text":"<p>For each paired-end input, make sure the corresponding read is in the same position in the input list. For example, two  pairs of paired-end files \u2013 <code>one_R1.fastq</code>, <code>one_R2.fastq</code>, <code>two_R1.fastq</code>, <code>two_R2.fastq</code> \u2013 should be passed to  Toolchest as:</p> <pre><code>tc.centrifuge(\n  read_one=[\"one_R1.fastq\", \"two_R1.fastq\"],\n  read_two=[\"one_R2.fastq\", \"two_R2.fastq\"],\n  ...\n)\n</code></pre>"},{"location":"tool-reference/taxonomic-classifiers/centrifuge/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 1.0.4 of Centrifuge.</p>"},{"location":"tool-reference/taxonomic-classifiers/centrifuge/#databases","title":"Databases","text":"<p>Toolchest currently supports the following databases for Bowtie 2:</p> <code>database_name</code> <code>database_version</code> Description <code>centrifuge_refseq_bacteria_archaea_viral_human</code> <code>1</code> RefSeq, bacteria / archaea / viral / human, JHU source1 <p>1These database indexes were generated by the Langmead Lab at Johns Hopkins and can be found on the lab's database index page.</p>"},{"location":"tool-reference/taxonomic-classifiers/centrifuge/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<p>Most additional arguments not related to input, output, or multithreading are supported:</p> <ul> <li><code>-q</code></li> <li><code>--qseq</code></li> <li><code>-f</code></li> <li><code>-r</code></li> <li><code>-s</code>, <code>--skip</code></li> <li><code>-u</code>, <code>--upto</code></li> <li><code>-5</code>, <code>--trim5</code></li> <li><code>-3</code>, <code>--trim3</code></li> <li><code>--phred33</code></li> <li><code>--phred64</code></li> <li><code>--int-quals</code></li> <li><code>--ignore-quals</code></li> <li><code>--nofw</code></li> <li><code>--norc</code></li> <li><code>--min-hitlen</code></li> <li><code>-k</code></li> <li><code>--host-taxids</code></li> <li><code>--exclude-taxids</code></li> <li><code>--out-fmt</code></li> <li><code>--tab-fmt-cols</code></li> <li><code>-t</code>, <code>--time</code></li> <li><code>--qc-filter</code></li> <li><code>--seed</code></li> <li><code>--non-deterministic</code></li> </ul> <p>Set additional arguments with <code>tool_args</code>. For example: <code>tool_args=\"-f -k 10\"</code></p>"},{"location":"tool-reference/taxonomic-classifiers/kraken-2/","title":"Kraken 2","text":"<p>Kraken 2 is a fast and efficient tool for taxonomic sequence classification. For more information, see the tool's  GitHub repo and wiki.</p>"},{"location":"tool-reference/taxonomic-classifiers/kraken-2/#function-call","title":"Function Call","text":"<pre><code>tc.kraken2(\n    inputs,\n    read_one=None,\n    read_two=None,\n    output_path=None,\n    tool_args=\"\",\n    database_name=\"standard\",\n    database_version=\"1\",\n    remote_database_path=None,\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/taxonomic-classifiers/kraken-2/#function-arguments","title":"Function Arguments","text":"Argument Use in place of: Description <code>inputs</code> input file location Path to one or more files to use as input. If using <code>read_one</code> or <code>read_two</code>, this can be omitted. The files can be a local or remote, see Using Files. <code>read_one</code> <code>--paired</code>, input file location (optional) Path to R1 of paired-end read input files. The file can be a local or remote, see Using Files. <code>read_two</code> <code>--paired</code>, input file location (optional) Path to R2 of paired-end read input files. The file can be a local or remote, see Using Files. <code>output_path</code> output file location (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to Kraken 2. This should be a string of arguments like the command line. See Supported Additional Arguments for more details. <code>database_name</code> <code>--db</code> (optional) Name of database to use for Kraken 2 alignment. Defaults to <code>\"standard\"</code>. <code>database_version</code> <code>-db</code> (optional) Version of database to use for Kraken 2 alignment. Defaults to <code>\"1\"</code>. <code>remote_database_path</code> <code>-db</code> (optional) AWS S3 URI to a directory with your custom database. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>See the Databases section for more details.</p>"},{"location":"tool-reference/taxonomic-classifiers/kraken-2/#output-files","title":"Output Files","text":"<p>A Kraken 2 run will output 3 files into <code>output_path</code>:</p> <ul> <li><code>kraken2_output.txt</code>: Results outputted to <code>stdout</code>.</li> <li><code>kraken2_report.txt</code>: Report generated by the <code>--report</code> flag.</li> <li><code>kraken2_summary.txt</code>: Summary of sequences processed and classified, from Kraken 2's output to <code>stderr</code>.</li> </ul>"},{"location":"tool-reference/taxonomic-classifiers/kraken-2/#notes","title":"Notes","text":""},{"location":"tool-reference/taxonomic-classifiers/kraken-2/#paired-end-inputs","title":"Paired-end inputs","text":"<p>Paired-end read inputs can be set with either <code>inputs</code> or through <code>read_one</code> and <code>read_two</code>.</p> <p>If using <code>inputs</code>, use a list of two filepaths: <code>inputs=['/path/to/read_1', '/path_to/read_2']</code></p> <p>If using <code>read_one</code> and <code>read_two</code>, these take priority over <code>inputs</code>.</p>"},{"location":"tool-reference/taxonomic-classifiers/kraken-2/#custom-database-arguments","title":"Custom database arguments","text":"<p>If using <code>custom_database_path</code>, the given database will take priority over any database selected via <code>database_name</code> and <code>database_version</code>.</p>"},{"location":"tool-reference/taxonomic-classifiers/kraken-2/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 2.1.1 of Kraken 2.</p>"},{"location":"tool-reference/taxonomic-classifiers/kraken-2/#databases","title":"Databases","text":"<p>Toolchest currently supports the following databases for Kraken 2:</p> <code>database_name</code> <code>database_version</code> Description <code>standard</code> <code>1</code> RefSeq archaea, bacteria, viral, plasmid, human1, UniVec_Core1 <code>refseq_fungi</code> <code>20211120</code> RefSeq fungi, generated on 11/20/2021 <p>1This database index was generated by the Langmead Lab at Johns Hopkins and can be found on the lab's database index page.</p>"},{"location":"tool-reference/taxonomic-classifiers/kraken-2/#custom-databases","title":"Custom Databases","text":"<p>Toolchest supports custom databases hosted in S3, so long as they are accessible from Toolchest. Use the argument <code>custom_database_path</code> to set the S3 URI of the folder with the database index files.</p>"},{"location":"tool-reference/taxonomic-classifiers/kraken-2/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li><code>--bzip2-compressed</code></li> <li><code>--confidence</code></li> <li><code>--gzip-compressed</code></li> <li><code>--minimum-base-quality</code></li> <li><code>--minimum-hit-groups</code></li> <li><code>--paired</code></li> <li><code>--quick</code></li> <li><code>--use-names</code></li> </ul> <p>Additional arguments can be specified under the <code>tool_args</code> argument.</p> <p>Note: <code>--paired</code> will automatically be added if using paired-end reads (specifying both <code>read_one</code> and <code>read_two</code>).</p>"},{"location":"tool-reference/taxonomic-classifiers/metaphlan/","title":"MetaPhlAn","text":"<p>MetaPhlAn is a tool for profiling the composition of microbial communities. For more information, see the tool's  website or  Github wiki.</p>"},{"location":"tool-reference/taxonomic-classifiers/metaphlan/#function-call","title":"Function Call","text":"<pre><code>tc.metaphlan(\n    inputs,\n    output_path=None,\n    output_primary_name=\"out.txt\",\n    tool_args=\"\",\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/taxonomic-classifiers/metaphlan/#function-arguments","title":"Function Arguments","text":"Argument Use in place of: Description <code>inputs</code> input file location Path to one or more files to use as input. The files can be a local or remote, see Using Files. <code>output_path</code> output file location (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to MetaPhlAn. This should be a string of arguments like the command line. <code>output_primary_name</code> (optional) Sets the name of the main output file. Defaults to \"out.txt\" <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>See the Databases section for more details.</p>"},{"location":"tool-reference/taxonomic-classifiers/metaphlan/#output-files","title":"Output Files","text":"<p>A MetaPhlAn run will output 2 files into <code>output_path</code>:</p> <ul> <li><code>out.txt</code>: Results of the MetaPhlAn run.</li> <li><code>{input_file_name}.bowtie2out.txt</code>: The intermediate Bowtie 2 output file generated by MetaPhlAn. This can be passed in as input to quickly rerun with the same input. This is not generated if <code>--no-map</code>is passed via <code>tool_args</code></li> </ul>"},{"location":"tool-reference/taxonomic-classifiers/metaphlan/#tool-versions","title":"Tool Versions","text":"<p>Toolchest currently supports version 3.0.14 of MetaPhlAn.</p>"},{"location":"tool-reference/taxonomic-classifiers/metaphlan/#databases","title":"Databases","text":"<p>Toolchest currently supports the latest version of the <code>mpa_v30_CHOCOPhlAn_201901_marker_info</code> database. You can read more about the database on the Github wiki.</p>"},{"location":"tool-reference/workflows-meta-tools/humann3/","title":"HUMAnN 3","text":"<p>HUMAnN 3 is a workflow tool for profiling microbial pathways in metagenomic and metatranscriptomic data. To learn  more about the tool, check out its homepage and  GitHub repo.</p>"},{"location":"tool-reference/workflows-meta-tools/humann3/#function-call","title":"Function Call","text":"<pre><code>tc.humann3(\n    inputs,\n    output_path=None,\n    tool_args=\"\",\n    taxonomic_profile=None,\n    mode=tc.tools.humann3.HUMAnN3Mode.HUMANN,\n    input_pathways=None,\n    output_primary_name=None,\n    is_async=False,\n)\n</code></pre>"},{"location":"tool-reference/workflows-meta-tools/humann3/#function-arguments","title":"Function Arguments","text":"<p>See the Notes section below for more details.</p> Argument Use in place of: Description <code>inputs</code> <code>--input</code> Path to a single file that will be passed in as input. FASTA and FASTQ formats (gzip compressed or uncompressed) are supported. Uncompressed SAM/BAM and M8 inputs are also supported. The files can be a local or remote, see Using Files. <code>output_path</code> <code>--output</code> (optional) Path (directory) to where the output files will be downloaded. If omitted, skips download. The files can be a local or remote, see Using Files. <code>output_primary_name</code> (optional) (optional) If you're using a mode that produces an individual output file, set the name here. <code>taxonomic_profile</code> <code>--taxonomic-profile</code> (optional) Path to a MetaPhlAn output tsv (taxonomic profile). Significantly accelerates execution if  provided. See the HUMAnN 3 docs on the topic for more. <code>mode</code> <code>humann $MODE</code> (optional) (optional) If you're running a humann3 utility scripts, put it here! Defaults to executing raw <code>humann</code>. This is an enum, see the note below this table for more. <code>input_pathways</code> <code>--input-pathways</code> (optional) Path to input pathways from a  <code>humann</code> run for use with <code>humann_unpack_pathways</code> mode. <code>tool_args</code> all other arguments (optional) Additional arguments to be passed to MetaPhlAn. This should be a string of arguments like the command line. <code>is_async</code> Whether to run a job asynchronously.  See Async Runs for more. <p>Note on <code>mode</code>: <code>mode</code> is an enum, accessible at <code>tc.tools.humann.HUMAnN3Mode</code> \u2013 e.g.  <code>tc.tools.humann.HUMAnN3Mode.RENORM_TABLE</code>.</p>"},{"location":"tool-reference/workflows-meta-tools/humann3/#tool-versions","title":"Tool Versions","text":"<p>Toolchest supports version 3.1.1 of HUMAnN.</p>"},{"location":"tool-reference/workflows-meta-tools/humann3/#databases","title":"Databases","text":"<p>Toolchest currently supports the following databases for HUMAnN:</p> <code>database_name</code> <code>database_version</code> Description <code>ChocoPhlAn</code> N/A The ChocoPhlAn database, provided by the Huttenhower lab. This database is required, and is not user configurable. Used via the <code>--nucleotide-database</code> argument. <code>UniRef90</code> <code>1</code> The UniRef 90 database. Used via the <code>--protein-database</code> argument."},{"location":"tool-reference/workflows-meta-tools/humann3/#supported-additional-arguments","title":"Supported Additional Arguments","text":"<ul> <li>--bypass-nucleotide-index</li> <li>--bypass-nucleotide-search</li> <li>--bypass-prescreen</li> <li>--bypass-translated-search</li> <li>--metaphlan-options</li> <li>--prescreen-threshold</li> <li>--bowtie2-options</li> <li>--nucleotide-identity-threshold</li> <li>--nucleotide-query-coverage-threshold</li> <li>--nucleotide-subject-coverage-threshold\"</li> <li>--diamond-options</li> <li>--evalue</li> <li>--translated-identity-threshold</li> <li>--translated-query-coverage-threshold</li> <li>--translated-subject-coverage-threshold</li> <li>--gap-fill</li> <li>--minpath</li> <li>--pathways</li> <li>--xipe</li> <li>--annotation-gene-index</li> <li>--output-format</li> <li>--output-max-decimals</li> <li>--remove-column-description-output</li> <li>--remove-stratified-output</li> </ul> <p>Additional arguments can be specified under the <code>tool_args</code> argument.</p>"},{"location":"toolchest-hosted-cloud/instance-types/","title":"Instance Types","text":"Instance type vCPUs Memory (GB) GPU type compute-2 2 4 compute-4 4 8 compute-8 8 16 compute-16 16 32 compute-32 32 64 compute-48 48 96 compute-64 64 128 compute-96 96 192 general-2 2 8 general-4 4 16 general-8 8 32 general-16 16 64 general-32 32 128 general-48 48 192 general-64 64 256 general-96 96 384 gpu-V100 8 61 1  NVIDIA Tesla V100 with 16 GB of memory memory-16 2 16 memory-32 4 32 memory-64 8 64 memory-128 16 128 memory-256 32 256 memory-384 48 384 memory-512 64 512"},{"location":"toolchest-hosted-cloud/pricing/","title":"Toolchest-hosted pricing and instance types","text":"<p>By default, Toolchest jobs run in Toolchest's managed AWS account. The prices below are for resources that you spawn by  running Toolchest jobs. For information on running Toolchest in your own AWS account, see  Running Toolchest in your AWS account</p> <p>Toolchest Hosted Cloud pricing starts with a free allowance and moves to incremental billing, scaling as your usage  grows.</p> <p>Per-minute billing starts when the Toolchest instance begins executing, and stops immediately when a run finishes. You  can say goodbye to paying for idling cloud instances.</p>"},{"location":"toolchest-hosted-cloud/pricing/#free-tier","title":"Free tier","text":""},{"location":"toolchest-hosted-cloud/pricing/#compute","title":"Compute","text":"Service Free tier What can you run? vCPU 50 vCPU-hours A run that lasts 2 hours with 25 vCPUs. RAM 100 GB-hours A run that lasts 2 hours with 50 GB of RAM Disk 2 TB-hour A run that lasts 2 hours with 1 TB of disk space. Invocations 50 invocations 50 runs"},{"location":"toolchest-hosted-cloud/pricing/#files","title":"Files","text":"Service Free tier What can you run? Input and output files 100 GB A run with 40 GB of transferred input files and 60 GB of transferred output files. High speed reference DB storage 50 GB/mo A custom reference database for Kraken 2 that's 50 GB."},{"location":"toolchest-hosted-cloud/pricing/#growth-pricing","title":"Growth pricing","text":""},{"location":"toolchest-hosted-cloud/pricing/#compute_1","title":"Compute","text":"Service Cost Billing increment vCPU $0.084 per vCPU-hour Per minute, with a one minute minimum RAM $0.016 per GB-hour Per minute, with a one minute minimum Disk $0.009 per TB-hour Per minute, with a one minute minimum Invocation $0.10 per invocation Per run"},{"location":"toolchest-hosted-cloud/pricing/#files_1","title":"Files","text":"Service Cost Billing increment Input and output files $0.1 per GB Per GB High speed reference database storage $2.4 per GB-mo Per month, with at least one month <p>Input and output file pricing includes network data transfer and temporary storage</p> <p>Every input and output file includes free transfer to and from Toolchest infrastructure. The files are cached for one week (7 days) after the run is initialized.</p>"},{"location":"toolchest-hosted-cloud/pricing/#example-pricing-with-a-toolchest-hosted-bioinformatics-tool-kraken-2","title":"Example pricing with a Toolchest-hosted bioinformatics tool, Kraken 2","text":"<p>A Kraken 2 run with 2 GB of input files, 16 vCPUs, and 128 GB of RAM with 128 GB of disk space runs for 5 minutes. It produces 1 GB of output files, for a total of 3 GB of input and output files. This costs:</p> <ul> <li>3 GB of input and output files * $0.1 per GB = $0.3</li> <li>16 vCPUs * 0.08 hours * $0.084 per vCPU-hour = $0.10752</li> <li>128 GB of RAM * 0.08 hours * $0.016 per RAM GB-hour = $0.16384</li> <li>0.125 TB of disk * 0.08 hours * $0.009 per TB-hour = $0.00009</li> <li>1 invocation = $0.10</li> </ul> <p>For a total of $0.67</p>"},{"location":"toolchest-hosted-cloud/pricing/#example-pricing-with-a-custom-python-script","title":"Example pricing with a custom Python script","text":"<p>A custom Python3 script with 40 GB of input files, 32 vCPUs, and 64 GB of RAM with 256 GB of disk space runs for 30 minutes. It produces 10 GB of output files, for a total of 50 GB of input and output files. This costs:</p> <ul> <li>50 GB of input and output files * $0.1 per GB = $5</li> <li>32 vCPUs * 0.5 hours * $0.084 per vCPU-hour = $1.344</li> <li>64 GB of RAM * 0.5 hours * $0.016 per RAM GB-hour = $0.512</li> <li>0.25 TB of disk * 0.5 hours * $0.009 per TB-hour = $0.001125</li> <li>1 invocation = $0.10</li> </ul> <p>For a total of $6.96</p>"},{"location":"toolchest-hosted-cloud/pricing/#support","title":"Support","text":"<p>Every customer gets access to text-based support \u2013 including a shared Slack channel, email, and any other async way  that you can think of talking to us.</p> <p>We offer synchronous support, and SLAs for support and infrastructure availability, too.</p>"},{"location":"toolchest-hosted-cloud/pricing/#custom-plans","title":"Custom plans","text":"<p>If you're a business with unique needs (e.g. high volume, a non-standard business model, or very large files), we can  build a custom plan for you.</p>"},{"location":"toolchest-hosted-cloud/running-toolchest-in-your-aws-account/","title":"Running Toolchest in your AWS account","text":"<p>If you just want to enable Toolchest to pull from your S3 buckets, check out  Using AWS with Toolchest.</p> <p>You can also set up Toolchest to run instances in your own AWS account. We're gating this feature for now, so let us  know if you'd like access.</p>"}]}